package service

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"net"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/forward-mcp/internal/config"
	"github.com/forward-mcp/internal/forward"
	"github.com/forward-mcp/internal/logger"
	_ "github.com/mattn/go-sqlite3"
	mcp "github.com/metoro-io/mcp-golang"
)

// Arguments for get_nqe_result_chunks tool
// Either entity_id or (query_id, network_id, snapshot_id) must be provided
// Optionally, chunk_index can be used to fetch a single chunk
// If chunk_index is omitted, all chunks are returned
type GetNQEResultChunksArgs struct {
	EntityID   string `json:"entity_id" jsonschema:"required,description=Entity ID containing the NQE results"`
	QueryID    string `json:"query_id" jsonschema:"required,description=Query ID that was executed"`
	NetworkID  string `json:"network_id" jsonschema:"required,description=Network ID where the query was run"`
	SnapshotID string `json:"snapshot_id" jsonschema:"required,description=Snapshot ID used for the query"`
	ChunkIndex *int   `json:"chunk_index,omitempty" jsonschema:"description=Specific chunk index to retrieve (omit for all chunks)"`
}

// WorkflowState represents the current state of a user workflow
type WorkflowState struct {
	CurrentStep   string                 `json:"current_step"`
	Parameters    map[string]interface{} `json:"parameters"`
	SelectedQuery string                 `json:"selected_query"`
	NetworkID     string                 `json:"network_id"`
	SnapshotID    string                 `json:"snapshot_id"`
}

// WorkflowManager manages user workflow states
type WorkflowManager struct {
	sessions map[string]*WorkflowState
	mutex    sync.RWMutex
}

// NewWorkflowManager creates a new workflow manager
func NewWorkflowManager() *WorkflowManager {
	return &WorkflowManager{
		sessions: make(map[string]*WorkflowState),
	}
}

// GetState gets the workflow state for a session
func (wm *WorkflowManager) GetState(sessionID string) *WorkflowState {
	wm.mutex.RLock()
	defer wm.mutex.RUnlock()
	if state, exists := wm.sessions[sessionID]; exists {
		return state
	}
	return &WorkflowState{
		CurrentStep: "start",
		Parameters:  make(map[string]interface{}),
	}
}

// SetState sets the workflow state for a session
func (wm *WorkflowManager) SetState(sessionID string, state *WorkflowState) {
	wm.mutex.Lock()
	defer wm.mutex.Unlock()
	wm.sessions[sessionID] = state
}

// ForwardMCPService implements Forward Networks MCP tools using mcp-golang
type ForwardMCPService struct {
	forwardClient     forward.ClientInterface
	config            *config.Config
	logger            *logger.Logger
	instanceID        string // Unique identifier for this Forward Networks instance
	defaults          *ServiceDefaults
	workflowManager   *WorkflowManager
	semanticCache     *SemanticCache
	queryIndex        *NQEQueryIndex
	database          *NQEDatabase
	memorySystem      *MemorySystem       // Knowledge graph memory system
	apiTracker        *APIMemoryTracker   // API result tracking using memory system
	bloomManager      *BloomSearchManager // Bloom filter for efficient large result filtering
	bloomIndexManager *BloomIndexManager  // Persistent bloom index for large NQE results
	// Context cancellation for graceful shutdown
	ctx        context.Context
	cancelFunc context.CancelFunc
}

// ServiceDefaults holds default values for the MCP service
type ServiceDefaults struct {
	NetworkID  string
	SnapshotID string
	QueryLimit int
}

// NewForwardMCPService creates a new Forward MCP service
func NewForwardMCPService(cfg *config.Config, logger *logger.Logger) *ForwardMCPService {
	// Use configured instance ID or generate one based on API URL
	instanceID := cfg.Forward.InstanceID
	if instanceID == "" {
		instanceID = GenerateInstanceID(cfg.Forward.APIBaseURL)
		logger.Info("Using generated instance ID '%s' for partitioning (based on %s)", instanceID, cfg.Forward.APIBaseURL)
	} else {
		logger.Info("Using configured instance ID '%s' for partitioning", instanceID)
	}

	// Create Forward Networks client
	forwardClient := forward.NewClient(&cfg.Forward)

	// Create embedding service based on config
	var embeddingService EmbeddingService
	if cfg.Forward.SemanticCache.EmbeddingProvider == "openai" {
		if openaiKey := os.Getenv("OPENAI_API_KEY"); openaiKey != "" {
			embeddingService = NewOpenAIEmbeddingService(openaiKey)
		} else {
			embeddingService = NewKeywordEmbeddingService()
			logger.Warn("OpenAI provider selected but OPENAI_API_KEY not set - using keyword embedding service")
		}
	} else {
		embeddingService = NewKeywordEmbeddingService()
	}

	// Create semantic cache with instance partitioning
	semanticCache := NewSemanticCache(embeddingService, logger, instanceID, &cfg.Forward.SemanticCache)

	// Create database with instance partitioning
	database, err := NewNQEDatabase(logger, instanceID)
	if err != nil {
		logger.Error("Failed to create database: %v", err)
		// Continue without database - will fall back to spec file
		database = nil
	}

	// Create query index
	queryIndex := NewNQEQueryIndex(embeddingService, logger)

	// Create memory system
	memorySystem, err := NewMemorySystem(logger, instanceID)
	if err != nil {
		logger.Error("Failed to create memory system: %v", err)
		// Continue without memory system
		memorySystem = nil
	}

	// Create API memory tracker
	var apiTracker *APIMemoryTracker
	if memorySystem != nil {
		apiTracker = NewAPIMemoryTracker(memorySystem, logger, instanceID)
		logger.Info("API memory tracker initialized for tracking API results and relationships")
	}

	// Create bloom search manager for efficient large result filtering
	bloomManager := NewBloomSearchManager(logger, instanceID)
	logger.Info("Bloom search manager initialized for efficient large result filtering")

	// Create persistent bloom index manager for large NQE results
	bloomIndexDir := filepath.Join("data", "bloom_indexes", instanceID)
	bloomIndexManager := NewBloomIndexManager(logger, bloomIndexDir)
	logger.Info("Persistent bloom index manager initialized for large NQE results")

	// Create context for cancellation
	ctx, cancelFunc := context.WithCancel(context.Background())

	service := &ForwardMCPService{
		forwardClient: forwardClient,
		config:        cfg,
		logger:        logger,
		instanceID:    instanceID,
		defaults: &ServiceDefaults{
			NetworkID:  cfg.Forward.DefaultNetworkID,
			SnapshotID: cfg.Forward.DefaultSnapshotID,
			QueryLimit: cfg.Forward.DefaultQueryLimit,
		},
		workflowManager:   NewWorkflowManager(),
		semanticCache:     semanticCache,
		queryIndex:        queryIndex,
		database:          database,
		memorySystem:      memorySystem,
		apiTracker:        apiTracker,
		bloomManager:      bloomManager,
		bloomIndexManager: bloomIndexManager,
		ctx:               ctx,
		cancelFunc:        cancelFunc,
	}

	// Set up database callback to automatically refresh query index when database is updated
	if database != nil && queryIndex != nil {
		database.AddUpdateCallback(func() {
			logger.Info("üîÑ Database updated, automatically refreshing query index...")

			// Load updated queries from database
			queries, err := database.LoadQueries()
			if err != nil {
				logger.Warn("üîÑ Failed to load updated queries for index refresh: %v", err)
				return
			}

			// Refresh query index with updated data
			if err := queryIndex.LoadFromQueries(queries); err != nil {
				logger.Warn("üîÑ Failed to refresh query index after database update: %v", err)
			} else {
				logger.Info("üîÑ Query index automatically refreshed with %d queries", len(queries))

				// Check embedding coverage after refresh
				stats := queryIndex.GetStatistics()
				embeddedCount := stats["embedded_queries"].(int)
				if embeddedCount > 0 && embeddedCount < len(queries) {
					coverage := stats["embedding_coverage"].(float64)
					logger.Info("üß† AI embeddings coverage: %.1f%% (%d/%d queries)", coverage*100, embeddedCount, len(queries))
				}
			}
		})
		logger.Info("üîÑ Database update callback registered for automatic query index refresh")
	}

	// Initialize query index with existing data synchronously
	if database != nil {
		// Try to load existing queries from database first
		logger.Info("üîÑ Loading existing queries from database...")
		queries, err := database.LoadQueries()
		if err != nil {
			logger.Warn("üîÑ Failed to load queries from database: %v", err)
			// Fallback to spec file
			if err := queryIndex.LoadFromSpec(); err != nil {
				logger.Warn("üîÑ Failed to initialize query index from spec: %v", err)
			} else {
				logger.Info("üîÑ Query index initialized from spec file as fallback")
			}
		} else if len(queries) > 0 {
			// Load existing queries into index
			if err := queryIndex.LoadFromQueries(queries); err != nil {
				logger.Error("üîÑ Failed to load queries into index: %v", err)
				// Fallback to spec file
				if err := queryIndex.LoadFromSpec(); err != nil {
					logger.Warn("üîÑ Failed to initialize query index from spec: %v", err)
				} else {
					logger.Info("üîÑ Query index initialized from spec file as fallback")
				}
			} else {
				logger.Info("üîÑ Query index initialized with %d existing queries from database", len(queries))
				// Count enhanced queries for informational purposes
				enhancedCount := 0
				for _, q := range queries {
					if q.SourceCode != "" || q.Description != "" {
						enhancedCount++
					}
				}
				if enhancedCount > 0 {
					logger.Info("üöÄ Found %d queries with enhanced metadata (source code/descriptions)", enhancedCount)
				} else {
					logger.Info("üí° Tip: Run 'hydrate_database' with enhanced_mode for richer query metadata")
				}
			}
		} else {
			// Database is empty, load from spec file
			logger.Info("üîÑ Database is empty, initializing from spec file...")
			if err := queryIndex.LoadFromSpec(); err != nil {
				logger.Warn("üîÑ Failed to initialize query index from spec: %v", err)
			} else {
				logger.Info("üîÑ Query index initialized from spec file")
				logger.Info("üí° Tip: Run 'hydrate_database' to populate with live data from API")
			}
		}
	} else {
		// No database, fallback to spec file loading
		logger.Info("üîÑ No database available, loading from spec file...")
		if err := queryIndex.LoadFromSpec(); err != nil {
			logger.Warn("üîÑ Failed to initialize query index from spec: %v", err)
		} else {
			logger.Info("üîÑ Query index initialized from spec file")
		}
	}

	return service
}

// Shutdown gracefully shuts down the ForwardMCPService
func (s *ForwardMCPService) Shutdown(timeout time.Duration) error {
	s.logger.Info("Shutting down ForwardMCPService...")

	// Cancel the context
	s.cancelFunc()

	// Close database connection if it exists
	if s.database != nil {
		if err := s.database.Close(); err != nil {
			s.logger.Error("Failed to close database: %v", err)
			return fmt.Errorf("failed to close database: %w", err)
		}
	}

	// Close memory system if it exists
	if s.memorySystem != nil {
		if err := s.memorySystem.Close(); err != nil {
			s.logger.Error("Failed to close memory system: %v", err)
			return fmt.Errorf("failed to close memory system: %w", err)
		}
	}

	// Close bloom index manager
	if s.bloomIndexManager != nil {
		if err := s.bloomIndexManager.Close(); err != nil {
			s.logger.Error("Failed to close bloom index manager: %v", err)
		}
	}

	s.logger.Info("ForwardMCPService shutdown complete")
	return nil
}

// Helper function to get network ID with fallback to default
func (s *ForwardMCPService) getNetworkID(networkID string) string {
	if networkID != "" {
		return networkID
	}
	if s.defaults != nil {
		return s.defaults.NetworkID
	}
	return ""
}

// Helper function to get snapshot ID with fallback to default
func (s *ForwardMCPService) getSnapshotID(snapshotID string) string {
	if snapshotID != "" {
		return snapshotID
	}
	if s.defaults != nil {
		return s.defaults.SnapshotID
	}
	return ""
}

// Helper function to get query limit with fallback to default
func (s *ForwardMCPService) getQueryLimit(limit int) int {
	if limit > 0 {
		return limit
	}
	if s.defaults != nil {
		return s.defaults.QueryLimit
	}
	return 1000 // Default fallback if no defaults are set
}

// Helper function to log tool calls with detailed information (legacy compatibility)
func (s *ForwardMCPService) logToolCall(toolName string, args interface{}, err error) {
	// Use zero duration for legacy calls - timing will be handled at a higher level
	s.logger.LogToolCall(toolName, args, 0, err)
}

// Enhanced function to log tool calls with performance metrics
func (s *ForwardMCPService) logToolCallWithTiming(toolName string, args interface{}, duration time.Duration, err error) {
	s.logger.LogToolCall(toolName, args, duration, err)
}

// Wrapper function to time and log tool execution
func (s *ForwardMCPService) timeAndLogTool(toolName string, args interface{}, fn func() error) error {
	start := time.Now()
	err := fn()
	duration := time.Since(start)
	s.logToolCallWithTiming(toolName, args, duration, err)
	return err
}

// RegisterTools registers all Forward Networks tools with the MCP server
func (s *ForwardMCPService) RegisterTools(server *mcp.Server) error {
	// Network Management Tools
	if err := server.RegisterTool("list_networks",
		"List all networks in the Forward platform. Returns network IDs, names, and descriptions. Use this to discover available networks or find network IDs for other operations. Supports pagination (limit/offset) and memory storage for large datasets.",
		s.listNetworks); err != nil {
		return fmt.Errorf("failed to register list_networks tool: %w", err)
	}

	if err := server.RegisterTool("create_network",
		"Create a new network in the Forward platform. Requires a network name. Returns the new network with ID for subsequent operations.",
		s.createNetwork); err != nil {
		return fmt.Errorf("failed to register create_network tool: %w", err)
	}

	// if err := server.RegisterTool("delete_network",
	// 	"Delete a network from the Forward platform. Requires network_id. WARNING: This permanently deletes all associated data.",
	// 	s.deleteNetwork); err != nil {
	// 	return fmt.Errorf("failed to register delete_network tool: %w", err)
	// }

	if err := server.RegisterTool("update_network",
		"Update network properties in the Forward platform. Requires network_id and at least one property to update (name or description).",
		s.updateNetwork); err != nil {
		return fmt.Errorf("failed to register update_network tool: %w", err)
	}

	// Path Search Tools
	if err := server.RegisterTool("search_paths",
		"üîç **SINGLE PATH SEARCH**: Execute a single path search by tracing packets through the network.\n\nExecute path searches by tracing packets through the network. This tool is optimized for single path queries.\n\n**Source Specification Rules:**\n- **Option 1**: Use 'from' (device name) - API will use the device as source\n- **Option 2**: Use 'src_ip' (IP address/subnet) - API will resolve the IP to source locations\n- **Option 3**: Use both 'from' + 'src_ip' for precise packet header specification\n\n**Destination Specification:**\n- **REQUIRED**: 'dst_ip' must be a valid IP address or CIDR\n- **IMPORTANT**: Device names are NOT supported in dst_ip - use actual IP addresses\n\n**Best Practices:**\n- Use 'intent' parameter to control search behavior (PREFER_DELIVERED, PREFER_VIOLATIONS, VIOLATIONS_ONLY)\n- Set 'max_results' and 'max_candidates' to control response size and performance\n- Use 'max_seconds' for timeout control\n- 'snapshot_id' is optional - API uses latest processed snapshot if omitted\n\n**For multiple paths, use search_paths_bulk for better performance.**",
		s.searchPathsEntry); err != nil {
		return fmt.Errorf("failed to register search_paths tool: %w", err)
	}

	if err := server.RegisterTool("search_paths_bulk",
		"üöÄ **RECOMMENDED**: Use this tool for path searches (single or bulk) with better performance.\n\nExecute path searches by tracing packets through the network. Supports both single and bulk path searches.\n\n**Source Specification Rules:**\n- **Option 1**: Use 'from' (device name) - API will use the device as source\n- **Option 2**: Use 'src_ip' (IP address/subnet) - API will resolve the IP to source locations\n- **Option 3**: Use both 'from' + 'src_ip' for precise packet header specification\n\n**Destination Specification:**\n- **REQUIRED**: 'dst_ip' must be a valid IP address or CIDR\n- **IMPORTANT**: Device names are NOT supported in dst_ip - use actual IP addresses\n\n**Best Practices:**\n- Use 'intent' parameter to control search behavior (PREFER_DELIVERED, PREFER_VIOLATIONS, VIOLATIONS_ONLY)\n- Set 'max_results' and 'max_candidates' to control response size and performance\n- Use 'max_seconds' and 'max_overall_seconds' for timeout control\n- 'snapshot_id' is optional - API uses latest processed snapshot if omitted\n\n**Request Format:** Provide an array of path search queries, each with 'dst_ip' and either 'from' or 'src_ip'.",
		s.searchPathsBulkEntry); err != nil {
		return fmt.Errorf("failed to register search_paths_bulk tool: %w", err)
	}

	// Register network prefix analysis tool
	if err := server.RegisterTool("analyze_network_prefixes",
		"üîç **Network Prefix Discovery & Connectivity Analysis**\n\nDiscover network prefixes, map them to devices, and analyze connectivity between sites using different aggregation levels.\n\n**Capabilities:**\n- Discover network prefixes (/8, /16, /24, etc.) and map to devices\n- Analyze connectivity between sites using aggregated prefixes\n- Identify network topology patterns and connectivity gaps\n- Generate connectivity matrices for different aggregation levels\n\n**Use Cases:**\n- Site-to-site connectivity analysis\n- Network segmentation validation\n- Route aggregation verification\n- Multi-site network planning\n\n**Parameters:**\n- network_id: Target network for analysis\n- prefix_levels: Aggregation levels to analyze (e.g., ['/8', '/16', '/24'])\n- from_devices/to_devices: Specific devices to analyze\n- intent: Search intent (PREFER_DELIVERED, PREFER_VIOLATIONS, VIOLATIONS_ONLY)\n- max_results: Maximum results per analysis",
		s.analyzeNetworkPrefixes); err != nil {
		return fmt.Errorf("failed to register analyze_network_prefixes tool: %w", err)
	}

	// NQE Tools
	if err := server.RegisterTool("run_nqe_query_by_id",
		"üöÄ **RECOMMENDED**: Use this tool for standard network analysis and compliance checks.\n\nRun a Network Query Engine (NQE) query using a predefined query ID from the library. This is the preferred method for consistent, reliable network analysis.\n\n**Best Practices:**\n- Use 'all_results: true' to fetch complete datasets\n- Set appropriate 'limit' and 'offset' for pagination\n- Use 'parameters' for dynamic query customization\n- Check query descriptions with list_nqe_queries first\n\n**Performance Tips:**\n- Large results are automatically cached and chunked\n- Use semantic search to find relevant queries\n- Set reasonable limits to avoid timeouts",
		s.runNQEQueryByID); err != nil {
		return fmt.Errorf("failed to register run_nqe_query_by_id tool: %w", err)
	}

	if err := server.RegisterTool("list_nqe_queries",
		"üîç **DISCOVERY TOOL**: Find available NQE queries for your analysis needs.\n\nList available NQE queries from the Forward Networks query library. Use this to discover predefined queries for reports and analysis.\n\n**Usage Tips:**\n- Filter by directory (e.g., '/L3/Basic/', '/L3/Advanced/', '/L3/Security/')\n- Use search_nqe_queries for semantic search\n- Check query descriptions before running\n- Use query IDs with run_nqe_query_by_id",
		s.listNQEQueries); err != nil {
		return fmt.Errorf("failed to register list_nqe_queries tool: %w", err)
	}

	// First-Class Query Tools - Most Important Network Operations
	if err := server.RegisterTool("get_device_basic_info",
		"üìä **ESSENTIAL**: Get comprehensive device inventory information.\n\nGet basic device information including names, platforms, and management IPs. This is the primary tool for device discovery and inventory management.\n\n**What you get:**\n- Device names and types\n- Platform and OS information\n- Management IP addresses\n- Interface details\n- Device status and properties\n\n**Best Practices:**\n- Use this as your first step in network analysis\n- Set appropriate limits for large networks\n- Use filters to focus on specific device types\n- Combine with get_device_hardware for complete inventory",
		s.getDeviceBasicInfo); err != nil {
		return fmt.Errorf("failed to register get_device_basic_info tool: %w", err)
	}

	if err := server.RegisterTool("get_device_hardware",
		"üîß **HARDWARE INVENTORY**: Get detailed hardware information for lifecycle management.\n\nGet device hardware information including models, serial numbers, and hardware details. Critical for hardware inventory and lifecycle management.\n\n**What you get:**\n- Device models and serial numbers\n- Hardware specifications\n- Vendor and platform details\n- Interface hardware information\n- Asset tracking data\n\n**Use Cases:**\n- Hardware refresh planning\n- Asset inventory management\n- Support contract validation\n- Capacity planning",
		s.getDeviceHardware); err != nil {
		return fmt.Errorf("failed to register get_device_hardware tool: %w", err)
	}

	if err := server.RegisterTool("get_hardware_support",
		"‚ö†Ô∏è **COMPLIANCE CRITICAL**: Check hardware support status for security and compliance.\n\nGet hardware support status including end-of-life and support dates. Essential for compliance and planning hardware refreshes.\n\n**What you get:**\n- End-of-life dates\n- Support contract status\n- Security vulnerability information\n- Recommended upgrade paths\n- Compliance status\n\n**Critical Use Cases:**\n- Security compliance audits\n- Hardware refresh planning\n- Risk assessment\n- Budget planning for upgrades",
		s.getHardwareSupport); err != nil {
		return fmt.Errorf("failed to register get_hardware_support tool: %w", err)
	}

	if err := server.RegisterTool("get_os_support",
		"üîí **SECURITY ESSENTIAL**: Check OS support status for security compliance.\n\nGet operating system support status including OS versions and support dates. Critical for security compliance and OS upgrade planning.\n\n**What you get:**\n- OS version information\n- Support end dates\n- Security patch status\n- Upgrade recommendations\n- Compliance status\n\n**Security Use Cases:**\n- Security compliance audits\n- Vulnerability assessment\n- Patch management planning\n- OS upgrade planning",
		s.getOSSupport); err != nil {
		return fmt.Errorf("failed to register get_os_support tool: %w", err)
	}

	if err := server.RegisterTool("search_configs",
		"üîç **CONFIGURATION SEARCH**: Search device configurations for specific patterns and settings.\n\nSearch device configurations for specific patterns, commands, or settings. Use this to find specific configurations across your network.\n\n**Pattern Examples:**\n```\ninterface\n  zone-member security\n  ip address {ip:string}\n```\n\n**Best Practices:**\n- Use hierarchical patterns with indentation\n- Extract variables with {name:type} syntax\n- Filter by device names for targeted searches\n- Use specific patterns for better results\n\n**Common Use Cases:**\n- Find specific interface configurations\n- Locate security policies\n- Identify routing configurations\n- Audit configuration compliance",
		s.searchConfigs); err != nil {
		return fmt.Errorf("failed to register search_configs tool: %w", err)
	}

	if err := server.RegisterTool("get_config_diff",
		"Compare network configurations between snapshots to identify changes. Essential for change tracking and troubleshooting configuration drift.",
		s.getConfigDiff); err != nil {
		return fmt.Errorf("failed to register get_config_diff tool: %w", err)
	}

	// Device Management Tools
	if err := server.RegisterTool("list_devices",
		"List devices in a network. Requires network_id. Returns basic device inventory with names, types, and status. Supports pagination with limit and offset. Use for device discovery and inventory management.",
		s.listDevices); err != nil {
		return fmt.Errorf("failed to register list_devices tool: %w", err)
	}

	if err := server.RegisterTool("get_device_locations",
		"Get device location mappings for a network. Requires network_id. Shows which devices are assigned to which physical locations. Use for topology planning and device organization.",
		s.getDeviceLocations); err != nil {
		return fmt.Errorf("failed to register get_device_locations tool: %w", err)
	}

	// Snapshot Management Tools
	if err := server.RegisterTool("list_snapshots",
		"List network configuration snapshots. Requires network_id. Shows historical network states with timestamps and status. Use to view configuration history and find specific snapshots for queries. Supports pagination (limit/offset) and memory storage for large datasets.",
		s.listSnapshots); err != nil {
		return fmt.Errorf("failed to register list_snapshots tool: %w", err)
	}

	if err := server.RegisterTool("get_latest_snapshot",
		"Get the latest processed snapshot for a network. Requires network_id. Returns the most recent network state. Use to ensure queries run against current configuration.",
		s.getLatestSnapshot); err != nil {
		return fmt.Errorf("failed to register get_latest_snapshot tool: %w", err)
	}

	if err := server.RegisterTool("delete_snapshot",
		"Delete a network snapshot. Requires snapshot_id. WARNING: This permanently removes the snapshot and associated historical data. Use with caution for cleanup of old snapshots.",
		s.deleteSnapshot); err != nil {
		return fmt.Errorf("failed to register delete_snapshot tool: %w", err)
	}

	// Location Management Tools
	if err := server.RegisterTool("list_locations",
		"List locations in a network. Requires network_id. Returns physical locations with names and coordinates. Use to view network topology and organize devices by location. Supports pagination (limit/offset) and memory storage for large datasets. Default limit is 25 to prevent token overflow.",
		s.listLocations); err != nil {
		return fmt.Errorf("failed to register list_locations tool: %w", err)
	}

	if err := server.RegisterTool("create_location",
		"Create a new location in a network. Requires network_id, location name, latitude, and longitude. Optional city, adminDivision, and country. Use to set up new sites or data centers for device organization.",
		s.createLocation); err != nil {
		return fmt.Errorf("failed to register create_location tool: %w", err)
	}

	if err := server.RegisterTool("update_location",
		"Update an existing location in a network. Requires network_id and location_id. Optional new name, description, latitude, and longitude. Use to modify location details.",
		s.updateLocation); err != nil {
		return fmt.Errorf("failed to register update_location tool: %w", err)
	}

	if err := server.RegisterTool("delete_location",
		"Delete a location from a network. Requires network_id and location_id. Use to remove locations that are no longer needed.",
		s.deleteLocation); err != nil {
		return fmt.Errorf("failed to register delete_location tool: %w", err)
	}

	if err := server.RegisterTool("create_locations_bulk",
		"Create or update multiple network locations in a single operation. Requires network_id and an array of locations. Uses PATCH /api/networks/{networkId}/locations. Locations with existing IDs will be updated, others will be created.",
		s.createLocationsBulk); err != nil {
		return fmt.Errorf("failed to register create_locations_bulk tool: %w", err)
	}

	if err := server.RegisterTool("update_device_locations",
		"Update device location assignments in bulk. Requires network_id and a map of device IDs to location IDs. Use to assign multiple devices to their physical locations efficiently. Note: Cloud devices (CSR1KV, PAN-FW, etc.) cannot be moved to physical locations.",
		s.updateDeviceLocations); err != nil {
		return fmt.Errorf("failed to register update_device_locations tool: %w", err)
	}

	// Default Settings Management Tools
	if err := server.RegisterTool("get_default_settings",
		"View current default settings for network operations. Shows the default network ID, snapshot ID, and query limits configured for this session.",
		s.getDefaultSettings); err != nil {
		return fmt.Errorf("failed to register get_default_settings tool: %w", err)
	}

	if err := server.RegisterTool("set_default_network",
		"Set the default network for all operations. Accepts either a network ID or network name. This will be used when network_id is not specified in other tools.",
		s.setDefaultNetwork); err != nil {
		return fmt.Errorf("failed to register set_default_network tool: %w", err)
	}

	// Semantic Cache and AI Enhancement Tools
	if err := server.RegisterTool("get_cache_stats",
		"View semantic cache performance statistics including hit rates, total queries, and cache efficiency metrics.",
		s.getCacheStats); err != nil {
		return fmt.Errorf("failed to register get_cache_stats tool: %w", err)
	}

	if err := server.RegisterTool("suggest_similar_queries",
		"Get suggestions for similar NQE queries based on semantic similarity to your query intent. Helps discover relevant existing queries.",
		s.suggestSimilarQueries); err != nil {
		return fmt.Errorf("failed to register suggest_similar_queries tool: %w", err)
	}

	if err := server.RegisterTool("clear_cache",
		"Clear expired entries from the semantic cache to free up memory and improve performance.",
		s.clearCache); err != nil {
		return fmt.Errorf("failed to register clear_cache tool: %w", err)
	}

	// AI-Powered Query Discovery Tools
	if err := server.RegisterTool("search_nqe_queries",
		"üß† **AI-POWERED SEARCH**: Find relevant NQE queries using natural language.\n\nAI-powered search through 6000+ predefined NQE queries using natural language. Describe what you want to analyze and get relevant query suggestions.\n\n**Best Practices:**\n- Be specific and descriptive in your query\n- Use examples like 'AWS security issues', 'BGP routing problems'\n- Avoid vague terms like 'network' or 'config'\n- Use category filters to narrow results\n\n**Example Queries:**\n- 'show me AWS security vulnerabilities'\n- 'find BGP routing issues'\n- 'check interface utilization'\n- 'devices with high CPU usage'\n\n**Note:** For executable queries, use find_executable_query instead.",
		s.searchNQEQueries); err != nil {
		return fmt.Errorf("failed to register search_nqe_queries tool: %w", err)
	}

	// Bulk location setup workflow (guides bulk upsert using PATCH)
	if err := server.RegisterPrompt("bulk_location_setup", "Guide to bulk create or update network locations", func(args struct {
		SessionID string `json:"session_id,omitempty"`
	}) (*mcp.PromptResponse, error) {
		content := "" +
			"You can create or update multiple locations in bulk using PATCH.\n\n" +
			"- Use create_locations_bulk for both creating new locations and updating existing ones.\n" +
			"- Locations with existing IDs will be updated, others will be created.\n" +
			"- Either 'id' (for updates) or 'name' (for creates) must be provided for each location.\n\n" +
			"Example request for create_locations_bulk:\n" +
			"{" +
			"\"network_id\": \"12345\",\n" +
			"\"locations\": [\n" +
			"  { \"id\": \"dyt-a\", \"name\": \"Dayton DC Updated\", \"lat\": 39.8113, \"lng\": -84.2722 },\n" +
			"  { \"name\": \"NY Edge\", \"lat\": 40.7128, \"lng\": -74.0060, \"city\": \"New York\" }\n" +
			"]}\n\n" +
			"Tip: This is safe to run multiple times - existing locations will be updated, new ones created."
		return mcp.NewPromptResponse("Bulk Location Setup", mcp.NewPromptMessage(mcp.NewTextContent(content), mcp.RoleAssistant)), nil
	}); err != nil {
		return fmt.Errorf("failed to register bulk_location_setup prompt: %w", err)
	}

	if err := server.RegisterTool("initialize_query_index",
		"Initialize or rebuild the AI-powered NQE query index from the spec file. REQUIRED before using search_nqe_queries or find_executable_query. Run this once at startup or when you get 'query index is empty' errors. Can generate embeddings for semantic search if OpenAI API key is available.",
		s.initializeQueryIndex); err != nil {
		return fmt.Errorf("failed to register initialize_query_index tool: %w", err)
	}

	// Database Hydration Tools
	if err := server.RegisterTool("hydrate_database",
		"Hydrate the NQE database by loading queries from the Forward Networks API. Use this to refresh the database with latest query metadata and ensure optimal performance for search operations. Automatically refreshes the query index and optionally regenerates AI embeddings.",
		s.hydrateDatabase); err != nil {
		return fmt.Errorf("failed to register hydrate_database tool: %w", err)
	}

	if err := server.RegisterTool("refresh_query_index",
		"Refresh the query index from the current database content. Use this after hydrating the database to ensure the search index reflects the latest data.",
		s.refreshQueryIndex); err != nil {
		return fmt.Errorf("failed to register refresh_query_index tool: %w", err)
	}

	if err := server.RegisterTool("get_database_status",
		"Get the current status of the database and query index including query counts, last update times, and performance metrics.",
		s.getDatabaseStatus); err != nil {
		return fmt.Errorf("failed to register get_database_status tool: %w", err)
	}

	// Memory Management Tools
	if err := server.RegisterTool("create_entity",
		"Create a new entity in the knowledge graph memory system. Entities represent people, networks, devices, projects, or any other important concept to remember.",
		s.createEntity); err != nil {
		return fmt.Errorf("failed to register create_entity tool: %w", err)
	}

	if err := server.RegisterTool("create_relation",
		"Create a relation between two entities in the knowledge graph. Relations represent how entities are connected (e.g., 'owns', 'manages', 'depends_on').",
		s.createRelation); err != nil {
		return fmt.Errorf("failed to register create_relation tool: %w", err)
	}

	if err := server.RegisterTool("add_observation",
		"Add an observation to an entity. Observations are additional facts, notes, preferences, or behaviors associated with an entity.",
		s.addObservation); err != nil {
		return fmt.Errorf("failed to register add_observation tool: %w", err)
	}

	if err := server.RegisterTool("search_entities",
		"Search for entities in the knowledge graph by name, type, or observation content. Use this to find information you've stored about people, networks, or concepts.",
		s.searchEntities); err != nil {
		return fmt.Errorf("failed to register search_entities tool: %w", err)
	}

	if err := server.RegisterTool("get_entity",
		"Retrieve a specific entity by ID or name. Use this to get detailed information about a specific person, network, device, or concept.",
		s.getEntity); err != nil {
		return fmt.Errorf("failed to register get_entity tool: %w", err)
	}

	if err := server.RegisterTool("get_relations",
		"Get all relations for a specific entity. Use this to understand how an entity is connected to others in the knowledge graph.",
		s.getRelations); err != nil {
		return fmt.Errorf("failed to register get_relations tool: %w", err)
	}

	if err := server.RegisterTool("get_observations",
		"Get all observations for a specific entity. Use this to retrieve all stored facts, notes, and preferences about an entity.",
		s.getObservations); err != nil {
		return fmt.Errorf("failed to register get_observations tool: %w", err)
	}

	if err := server.RegisterTool("delete_entity",
		"Delete an entity and all its relations and observations. Use with caution as this permanently removes all stored information about the entity.",
		s.deleteEntity); err != nil {
		return fmt.Errorf("failed to register delete_entity tool: %w", err)
	}

	if err := server.RegisterTool("delete_relation",
		"Delete a specific relation between entities. Use this to remove connections that are no longer relevant.",
		s.deleteRelation); err != nil {
		return fmt.Errorf("failed to register delete_relation tool: %w", err)
	}

	if err := server.RegisterTool("delete_observation",
		"Delete a specific observation from an entity. Use this to remove outdated or incorrect information.",
		s.deleteObservation); err != nil {
		return fmt.Errorf("failed to register delete_observation tool: %w", err)
	}

	if err := server.RegisterTool("get_memory_stats",
		"Get statistics about the memory system including counts of entities, relations, and observations by type.",
		s.getMemoryStats); err != nil {
		return fmt.Errorf("failed to register get_memory_stats tool: %w", err)
	}

	// API Analytics Tools
	if err := server.RegisterTool("get_query_analytics",
		"Get analytics about query patterns and performance for a specific network. Shows query counts, execution times, result patterns, and usage trends from the memory system.",
		s.getQueryAnalytics); err != nil {
		return fmt.Errorf("failed to register get_query_analytics tool: %w", err)
	}

	// Instance Management Tools
	if err := server.RegisterTool("list_instance_ids",
		"List all available Forward Networks instance IDs in the database. Shows instance IDs with query counts and sync dates. Use this to find the correct instance ID to configure in FORWARD_INSTANCE_ID environment variable.",
		s.listInstanceIDs); err != nil {
		return fmt.Errorf("failed to register list_instance_ids tool: %w", err)
	}

	// Tool handler for get_nqe_result_chunks
	if err := server.RegisterTool("get_nqe_result_chunks",
		"Retrieve chunked NQE query results from the memory system. Provide either entity_id or (query_id, network_id, snapshot_id). Optionally, specify chunk_index to fetch a single chunk.",
		s.getNQEResultChunks); err != nil {
		return fmt.Errorf("failed to register get_nqe_result_chunks tool: %w", err)
	}

	// Add get_nqe_result_summary tool handler
	if err := server.RegisterTool("get_nqe_result_summary",
		"Get a summary of a stored NQE result (row count, columns, preview rows) by entity_id or (query_id, network_id, snapshot_id).",
		s.getNQEResultSummary); err != nil {
		return fmt.Errorf("failed to register get_nqe_result_summary tool: %w", err)
	}

	// Add analyze_nqe_result_sql tool handler
	if err := server.RegisterTool("analyze_nqe_result_sql",
		"Run a SQL query on a stored NQE result (by entity_id). Example: SELECT COUNT(*) FROM nqe_result;",
		s.analyzeNQEResultSQL); err != nil {
		return fmt.Errorf("failed to register analyze_nqe_result_sql tool: %w", err)
	}

	// Add bloom search tool handlers
	if err := server.RegisterTool("build_bloom_filter",
		"Build a bloom filter from NQE query results for efficient large dataset searching",
		s.buildBloomFilter); err != nil {
		return fmt.Errorf("failed to register build_bloom_filter tool: %w", err)
	}

	if err := server.RegisterTool("search_bloom_filter",
		"Search a bloom filter for matching items with sub-millisecond performance",
		s.searchBloomFilter); err != nil {
		return fmt.Errorf("failed to register search_bloom_filter tool: %w", err)
	}

	if err := server.RegisterTool("get_bloom_filter_stats",
		"Get statistics and performance metrics for all bloom filters",
		s.getBloomFilterStats); err != nil {
		return fmt.Errorf("failed to register get_bloom_filter_stats tool: %w", err)
	}

	return nil
}

// RegisterPrompts registers workflow prompts with the MCP server
func (s *ForwardMCPService) RegisterPrompts(server *mcp.Server) error {
	// Register NQE Query Discovery workflow as a prompt
	if err := server.RegisterPrompt("nqe_discovery", "Interactive NQE query discovery workflow to help find and run network queries", func(args NQEDiscoveryArgs) (*mcp.PromptResponse, error) {
		response, err := s.nqeQueryDiscoveryWorkflow(args)
		if err != nil {
			return nil, err
		}
		// Convert ToolResponse to PromptResponse
		if len(response.Content) > 0 {
			return mcp.NewPromptResponse("NQE Query Discovery", mcp.NewPromptMessage(response.Content[0], mcp.RoleAssistant)), nil
		}
		return mcp.NewPromptResponse("NQE Query Discovery", mcp.NewPromptMessage(mcp.NewTextContent("Welcome to NQE Query Discovery!"), mcp.RoleAssistant)), nil
	}); err != nil {
		return fmt.Errorf("failed to register nqe_discovery prompt: %w", err)
	}

	// Register Network Discovery workflow as a prompt
	if err := server.RegisterPrompt("network_discovery", "Interactive network discovery workflow to explore available networks and devices", func(args NetworkDiscoveryArgs) (*mcp.PromptResponse, error) {
		response, err := s.networkDiscoveryWorkflow(args)
		if err != nil {
			return nil, err
		}
		// Convert ToolResponse to PromptResponse
		if len(response.Content) > 0 {
			return mcp.NewPromptResponse("Network Discovery", mcp.NewPromptMessage(response.Content[0], mcp.RoleAssistant)), nil
		}
		return mcp.NewPromptResponse("Network Discovery", mcp.NewPromptMessage(mcp.NewTextContent("Network discovery workflow"), mcp.RoleAssistant)), nil
	}); err != nil {
		return fmt.Errorf("failed to register network_discovery prompt: %w", err)
	}

	// Register Large NQE Results Workflow as a prompt
	if err := server.RegisterPrompt("large_nqe_results_workflow", "Interactive workflow for handling large NQE query results with memory system storage and SQL analysis", func(args LargeNQEResultsWorkflowArgs) (*mcp.PromptResponse, error) {
		response, err := s.largeNQEResultsWorkflow(args)
		if err != nil {
			return nil, err
		}
		// Convert ToolResponse to PromptResponse
		if len(response.Content) > 0 {
			return mcp.NewPromptResponse("Large NQE Results Workflow", mcp.NewPromptMessage(response.Content[0], mcp.RoleAssistant)), nil
		}
		return mcp.NewPromptResponse("Large NQE Results Workflow", mcp.NewPromptMessage(mcp.NewTextContent("Welcome to Large NQE Results Workflow!"), mcp.RoleAssistant)), nil
	}); err != nil {
		return fmt.Errorf("failed to register large_nqe_results_workflow prompt: %w", err)
	}

	// Register Path Search Workflow as a prompt
	if err := server.RegisterPrompt("path_search_workflow", "Interactive workflow for effective path search using best practices including 'from' property and bulk operations", func(args PathSearchWorkflowArgs) (*mcp.PromptResponse, error) {
		response, err := s.pathSearchWorkflow(args)
		if err != nil {
			return nil, err
		}
		// Convert ToolResponse to PromptResponse
		if len(response.Content) > 0 {
			return mcp.NewPromptResponse("Path Search Workflow", mcp.NewPromptMessage(response.Content[0], mcp.RoleAssistant)), nil
		}
		return mcp.NewPromptResponse("Path Search Workflow", mcp.NewPromptMessage(mcp.NewTextContent("Welcome to Path Search Workflow!"), mcp.RoleAssistant)), nil
	}); err != nil {
		return fmt.Errorf("failed to register path_search_workflow prompt: %w", err)
	}

	// Register Network Prefix Discovery Workflow as a prompt
	if err := server.RegisterPrompt("network_prefix_discovery_workflow", "Interactive workflow for discovering network prefixes, mapping them to devices, and analyzing connectivity between sites using different aggregation levels", func(args NetworkPrefixDiscoveryArgs) (*mcp.PromptResponse, error) {
		response, err := s.networkPrefixDiscoveryWorkflow(args)
		if err != nil {
			return nil, err
		}
		// Convert ToolResponse to PromptResponse
		if len(response.Content) > 0 {
			return mcp.NewPromptResponse("Network Prefix Discovery Workflow", mcp.NewPromptMessage(response.Content[0], mcp.RoleAssistant)), nil
		}
		return mcp.NewPromptResponse("Network Prefix Discovery Workflow", mcp.NewPromptMessage(mcp.NewTextContent("Welcome to Network Prefix Discovery Workflow!"), mcp.RoleAssistant)), nil
	}); err != nil {
		return fmt.Errorf("failed to register network_prefix_discovery_workflow prompt: %w", err)
	}

	s.logger.Info("MCP ready - Forward Networks tools registered")
	return nil
}

// RegisterResources registers contextual resources with the MCP server
func (s *ForwardMCPService) RegisterResources(server *mcp.Server) error {
	// Register network context as a resource
	if err := server.RegisterResource("forward://network/context", "network_context", "Current network context including available networks and queries", "application/json", func() (*mcp.ResourceResponse, error) {
		context, err := s.getNetworkContext(NetworkContextArgs{})
		if err != nil {
			return nil, fmt.Errorf("failed to get network context: %w", err)
		}

		contextStr, ok := context.(string)
		if !ok {
			return nil, fmt.Errorf("network context is not a string")
		}

		return mcp.NewResourceResponse(mcp.NewTextEmbeddedResource("forward://network/context", contextStr, "application/json")), nil
	}); err != nil {
		return fmt.Errorf("failed to register network_context resource: %w", err)
	}

	s.logger.Debug("Successfully registered MCP resources")
	return nil
}

// nqeQueryDiscoveryWorkflow implements the NQE query discovery workflow
func (s *ForwardMCPService) nqeQueryDiscoveryWorkflow(args NQEDiscoveryArgs) (*mcp.ToolResponse, error) {
	sessionID := fmt.Sprintf("session_%v", args.SessionID) // In practice, extract from context
	state := s.workflowManager.GetState(sessionID)

	switch state.CurrentStep {
	case "start":
		return s.startQueryDiscovery(sessionID)
	case "category_selected":
		return s.listQueriesInCategory(sessionID, state.Parameters["directory"].(string))
	case "query_selected":
		return s.collectQueryParameters(sessionID)
	case "parameters_collected":
		return s.executeSelectedQuery(sessionID)
	default:
		return s.startQueryDiscovery(sessionID)
	}
}

// networkDiscoveryWorkflow implements the network discovery workflow
func (s *ForwardMCPService) networkDiscoveryWorkflow(args NetworkDiscoveryArgs) (*mcp.ToolResponse, error) {
	networks, err := s.forwardClient.GetNetworks()
	if err != nil {
		return nil, fmt.Errorf("failed to get networks: %w", err)
	}

	promptText := "Available networks:\n"
	for i, network := range networks {
		promptText += fmt.Sprintf("%d. %s (ID: %s)\n", i+1, network.Name, network.ID)
	}
	promptText += "\nWhat would you like to do?\n1. Select a network to explore\n2. Create a new network\n3. Search for specific devices"

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// largeNQEResultsWorkflow implements the large NQE results workflow
func (s *ForwardMCPService) largeNQEResultsWorkflow(args LargeNQEResultsWorkflowArgs) (*mcp.ToolResponse, error) {
	sessionID := fmt.Sprintf("session_%v", args.SessionID)
	state := s.workflowManager.GetState(sessionID)

	switch state.CurrentStep {
	case "start":
		return s.startLargeResultsWorkflow(sessionID)
	case "explain_process":
		return s.explainLargeResultsProcess(sessionID)
	case "show_example":
		return s.showLargeResultsExample(sessionID)
	case "demonstrate_sql":
		return s.demonstrateSQLAnalysis(sessionID)
	default:
		return s.startLargeResultsWorkflow(sessionID)
	}
}

// startLargeResultsWorkflow begins the large NQE results workflow
func (s *ForwardMCPService) startLargeResultsWorkflow(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "explain_process",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	promptText := `üîç **Large NQE Results Workflow Guide**

Welcome! This workflow teaches you how to handle large NQE query results efficiently using our memory system and SQL analysis capabilities.

**What you'll learn:**
1. How large results are automatically stored in chunks
2. How to retrieve and analyze stored results
3. How to use SQL queries for complex data analysis
4. Best practices for working with large datasets

**Key Concepts:**
- **Chunking**: Large results are split into 200-row chunks for LLM-friendly processing
- **Memory System**: Results are stored persistently with metadata and summaries
- **SQL Analysis**: Full SQL query capabilities on stored data
- **Entity Management**: Each result gets a unique entity ID for easy reference

Would you like to:
1. Learn about the process step-by-step
2. See a practical example
3. Try SQL analysis on existing data
4. Get best practices and tips

Which would you prefer?`

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// explainLargeResultsProcess explains the large results workflow process
func (s *ForwardMCPService) explainLargeResultsProcess(sessionID string) (*mcp.ToolResponse, error) {
	state := s.workflowManager.GetState(sessionID)
	state.CurrentStep = "show_example"
	s.workflowManager.SetState(sessionID, state)

	promptText := `üìã **Large NQE Results Process Explained**

**Step 1: Automatic Detection & Storage**
When you run an NQE query with "all_results: true" or when results exceed size limits:
- System automatically detects large result sets
- Results are fetched in batches using pagination
- Data is stored in the memory system with chunking (200 rows per chunk)
- Each result gets a unique entity ID for easy reference

**Step 2: Memory System Storage**
- **Entity Creation**: Creates a result entity with metadata (query_id, network_id, snapshot_id, row_count)
- **Chunking**: Splits data into manageable chunks stored as observations
- **Summary**: Generates a summary observation with columns, row count, and metadata
- **Persistence**: All data is stored in SQLite database for later retrieval

**Step 3: Analysis Tools Available**
- **get_nqe_result_summary**: View metadata and structure of stored results
- **get_nqe_result_chunks**: Retrieve raw data chunks (all or specific chunk)
- **analyze_nqe_result_sql**: Run SQL queries on the complete dataset

**Step 4: SQL Analysis Workflow**
- Retrieve all chunks for an entity
- Reconstruct complete dataset in memory
- Create temporary SQLite database with the data
- Execute your SQL queries
- Return formatted results

**Benefits:**
‚úÖ **No API Limits**: Work with unlimited data sizes
‚úÖ **Persistent Storage**: Results remain available across sessions
‚úÖ **SQL Power**: Full SQL query capabilities for complex analysis
‚úÖ **LLM Friendly**: Chunked data is easier for LLMs to process
‚úÖ **Performance**: Avoid re-running expensive queries

Would you like to see a practical example of this workflow?`

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// showLargeResultsExample shows a practical example
func (s *ForwardMCPService) showLargeResultsExample(sessionID string) (*mcp.ToolResponse, error) {
	state := s.workflowManager.GetState(sessionID)
	state.CurrentStep = "demonstrate_sql"
	s.workflowManager.SetState(sessionID, state)

	promptText := `üí° **Practical Example: Device Inventory Analysis**

**Scenario**: You want to analyze all devices in your network, but the result is too large for direct API response.

**Step 1: Run Query with Large Results**
{
  "tool": "run_nqe_query_by_id",
  "arguments": {
    "query_id": "device_basic_info",
    "network_id": "your_network_id",
    "all_results": true
  }
}

**Step 2: System Response**
Fetched all results in batches.
Total items: 1,247
Columns: [device_name, platform, ip_address, status, location]
Preview (first 5 rows): [...]
Stored in memory system as entity: device_basic_info-your_network_id-latest
You can use get_nqe_result_summary to analyze this result locally.

**Step 3: Get Result Summary**
{
  "tool": "get_nqe_result_summary",
  "arguments": {
    "entity_id": "device_basic_info-your_network_id-latest"
  }
}

**Step 4: SQL Analysis Examples**
{
  "tool": "analyze_nqe_result_sql",
  "arguments": {
    "entity_id": "device_basic_info-your_network_id-latest",
    "sql_query": "SELECT platform, COUNT(*) as count FROM nqe_result GROUP BY platform ORDER BY count DESC"
  }
}

**Common SQL Queries:**
- "SELECT COUNT(*) FROM nqe_result" - Total devices
- "SELECT status, COUNT(*) FROM nqe_result GROUP BY status" - Status breakdown
- "SELECT * FROM nqe_result WHERE status = 'down'" - Down devices
- "SELECT platform, AVG(CAST(ip_address AS INTEGER)) FROM nqe_result GROUP BY platform" - Platform analysis

Would you like to try SQL analysis on some existing data?`

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// demonstrateSQLAnalysis demonstrates SQL analysis capabilities
func (s *ForwardMCPService) demonstrateSQLAnalysis(sessionID string) (*mcp.ToolResponse, error) {
	state := s.workflowManager.GetState(sessionID)
	state.CurrentStep = "start"
	s.workflowManager.SetState(sessionID, state)

	promptText := `üöÄ **SQL Analysis Capabilities**

**Available SQL Features:**
- **Full SQLite Support**: All standard SQL operations
- **Aggregation**: COUNT, SUM, AVG, MIN, MAX, GROUP BY
- **Filtering**: WHERE clauses with complex conditions
- **Sorting**: ORDER BY with multiple columns
- **Joins**: Self-joins within the same dataset
- **Subqueries**: Nested queries for complex analysis
- **Functions**: String, numeric, and date functions

**Best Practices:**
1. **Always use LIMIT** for large result sets (system adds LIMIT 100 by default)
2. **Use GROUP BY** for aggregations and summaries
3. **Leverage WHERE** for filtering before aggregation
4. **Consider data types** - all columns are stored as TEXT initially
5. **Use CAST()** for numeric operations on text columns

**Example Workflows:**
- **Compliance Audit**: Count devices by platform, status, location
- **Performance Analysis**: Find devices with specific configurations
- **Security Assessment**: Identify devices with open ports or weak policies
- **Capacity Planning**: Analyze resource utilization patterns

**Next Steps:**
1. Run a query with "all_results: true" to get a large dataset
2. Use "get_nqe_result_summary" to understand the data structure
3. Write SQL queries to analyze the data
4. Use the results for reports, dashboards, or further analysis

**Pro Tips:**
- Store frequently used queries as entities for quick access
- Use the memory system to track analysis results over time
- Combine multiple query results for comprehensive analysis
- Export SQL results for external reporting tools

Ready to try this workflow with your own data? Start by running a query with "all_results: true"!`

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// getNetworkContext provides contextual network information as a resource
func (s *ForwardMCPService) getNetworkContext(args NetworkContextArgs) (interface{}, error) {
	networks, err := s.forwardClient.GetNetworks()
	if err != nil {
		return nil, fmt.Errorf("failed to get network context: %w", err)
	}

	context := map[string]interface{}{
		"networks":          networks,
		"timestamp":         "current",
		"available_queries": []string{"/L3/Basic/", "/L3/Advanced/", "/L3/Security/"},
	}

	contextJSON, _ := json.MarshalIndent(context, "", "  ")
	return string(contextJSON), nil
}

// startQueryDiscovery begins the NQE query discovery workflow
func (s *ForwardMCPService) startQueryDiscovery(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "category_selection",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	promptText := "Welcome to NQE Query Discovery!\n\nSelect a query category:\n1. Basic (/L3/Basic/) - Device inventory, basic connectivity\n2. Advanced (/L3/Advanced/) - Complex routing, performance analysis\n3. Security (/L3/Security/) - Security policies, compliance\n\nWhich category interests you?"
	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// listQueriesInCategory lists available queries in the selected category
func (s *ForwardMCPService) listQueriesInCategory(sessionID, directory string) (*mcp.ToolResponse, error) {
	queries, err := s.forwardClient.GetNQEQueries(directory)
	if err != nil {
		return nil, fmt.Errorf("failed to get queries: %w", err)
	}

	state := s.workflowManager.GetState(sessionID)
	state.CurrentStep = "query_selection"
	state.Parameters["directory"] = directory
	s.workflowManager.SetState(sessionID, state)

	promptText := fmt.Sprintf("Available queries in %s:\n", directory)
	for i, query := range queries {
		promptText += fmt.Sprintf("%d. %s (ID: %s)\n   Purpose: %s\n", i+1, query.Path, query.QueryID, query.Intent)
	}
	promptText += "\nWhich query would you like to run?"

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// collectQueryParameters collects parameters needed for the selected query
func (s *ForwardMCPService) collectQueryParameters(sessionID string) (*mcp.ToolResponse, error) {
	state := s.workflowManager.GetState(sessionID)

	// Check if we have network_id
	if _, exists := state.Parameters["network_id"]; !exists {
		return mcp.NewToolResponse(mcp.NewTextContent("Missing required parameter: network_id")), nil
	}

	// Check if we have snapshot_id
	if _, exists := state.Parameters["snapshot_id"]; !exists {
		return mcp.NewToolResponse(mcp.NewTextContent("Missing required parameter: snapshot_id")), nil
	}

	// All parameters collected, ready to execute
	state.CurrentStep = "ready_to_execute"
	s.workflowManager.SetState(sessionID, state)

	return mcp.NewToolResponse(mcp.NewTextContent("All parameters collected! Ready to execute query. Proceed?")), nil
}

// executeSelectedQuery executes the query with collected parameters
// This function is part of the workflow system that is now activated via MCP prompt registration
func (s *ForwardMCPService) executeSelectedQuery(sessionID string) (*mcp.ToolResponse, error) {
	state := s.workflowManager.GetState(sessionID)

	params := &forward.NQEQueryParams{
		NetworkID:  state.NetworkID,
		QueryID:    state.SelectedQuery,
		SnapshotID: state.SnapshotID,
	}

	result, err := s.forwardClient.RunNQEQueryByID(params)
	if err != nil {
		return nil, fmt.Errorf("failed to execute query: %w", err)
	}

	resultJSON, _ := json.MarshalIndent(result, "", "  ")
	promptText := fmt.Sprintf("Query executed successfully! Found %d results:\n%s\n\nWhat would you like to do next?\n1. Export results\n2. Run another query\n3. Get more details\n4. Exit", len(result.Items), string(resultJSON))

	return mcp.NewToolResponse(mcp.NewTextContent(promptText)), nil
}

// Network Observability Tool Implementations
func (s *ForwardMCPService) listNetworks(args ListNetworksArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("list_networks", args, nil)

	// Get all networks from API
	allNetworks, err := s.forwardClient.GetNetworks()
	if err != nil {
		return nil, fmt.Errorf("failed to list networks: %w", err)
	}

	// Apply pagination with safe defaults to prevent token overflow
	limit := args.Limit
	if limit <= 0 {
		limit = 25 // Conservative default limit to prevent token overflow
	}
	if limit > 100 {
		limit = 100 // Cap at 100 to prevent excessive responses
	}
	offset := args.Offset
	if offset < 0 {
		offset = 0
	}

	var networks []forward.Network
	var totalCount int
	var hasMore bool

	if args.AllResults {
		// Store all networks in memory system for large datasets
		networks = allNetworks
		totalCount = len(allNetworks)
		hasMore = false

		// Store in memory system if available
		if s.memorySystem != nil {
			entity, err := s.memorySystem.CreateEntity("network_list", "query_result", map[string]interface{}{
				"query_type":  "list_networks",
				"total_count": totalCount,
				"timestamp":   time.Now().Unix(),
			})
			if err == nil {
				// Store the networks data
				networksJSON, _ := json.Marshal(networks)
				s.memorySystem.AddObservation(entity.ID, string(networksJSON), "data", map[string]interface{}{
					"data_type": "networks_list",
					"count":     totalCount,
				})
			}
		}
	} else {
		// Apply pagination
		totalCount = len(allNetworks)
		start := offset
		end := offset + limit
		if start >= totalCount {
			networks = []forward.Network{}
		} else {
			if end > totalCount {
				end = totalCount
			}
			networks = allNetworks[start:end]
		}
		hasMore = offset+len(networks) < totalCount
	}

	// Build response
	var responseText strings.Builder
	responseText.WriteString(fmt.Sprintf("Found %d networks", totalCount))
	if !args.AllResults {
		responseText.WriteString(fmt.Sprintf(" (showing %d-%d)", offset+1, offset+len(networks)))
		if hasMore {
			responseText.WriteString(fmt.Sprintf(", %d more available", totalCount-offset-len(networks)))
		}
		if args.Limit <= 0 {
			responseText.WriteString(" [Note: Using default limit of 25 to prevent token overflow. Use 'limit' parameter to adjust.]")
		}
	}
	responseText.WriteString(":\n")

	if len(networks) > 0 {
		result := MarshalCompactJSONString(networks)
		responseText.WriteString(result)
	} else {
		responseText.WriteString("No networks found.")
	}

	if args.AllResults && s.memorySystem != nil {
		responseText.WriteString(fmt.Sprintf("\n\nüíæ Stored %d networks in memory system for future reference.", totalCount))
	}

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}

func (s *ForwardMCPService) createNetwork(args CreateNetworkArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("create_network", args, nil)
	network, err := s.forwardClient.CreateNetwork(args.Name)
	if err != nil {
		return nil, fmt.Errorf("failed to create network: %w", err)
	}

	result, _ := json.MarshalIndent(network, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Network created successfully:\n%s", string(result)))), nil
}

func (s *ForwardMCPService) deleteNetwork(args DeleteNetworkArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("delete_network", args, nil)
	network, err := s.forwardClient.DeleteNetwork(args.NetworkID)
	if err != nil {
		return nil, fmt.Errorf("failed to delete network: %w", err)
	}

	result, _ := json.MarshalIndent(network, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Network deleted successfully:\n%s", string(result)))), nil
}

func (s *ForwardMCPService) updateNetwork(args UpdateNetworkArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("update_network", args, nil)
	update := &forward.NetworkUpdate{}
	if args.Name != "" {
		update.Name = &args.Name
	}
	if args.Description != "" {
		update.Description = &args.Description
	}

	network, err := s.forwardClient.UpdateNetwork(args.NetworkID, update)
	if err != nil {
		return nil, fmt.Errorf("failed to update network: %w", err)
	}

	result, _ := json.MarshalIndent(network, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Network updated successfully:\n%s", string(result)))), nil
}

// Path Search Tool Implementations

// SearchPathsBulkArgs represents arguments for bulk path search
type SearchPathsBulkArgs struct {
	NetworkID               string                `json:"network_id" jsonschema:"required,description=Network ID to search in"`
	SnapshotID              string                `json:"snapshot_id,omitempty" jsonschema:"description=Snapshot ID to use (optional, uses latest if omitted)"`
	Queries                 []PathSearchQueryArgs `json:"queries" jsonschema:"required,description=Array of path search queries to execute"`
	Intent                  string                `json:"intent,omitempty" jsonschema:"description=Search intent (PREFER_DELIVERED, PREFER_VIOLATIONS, VIOLATIONS_ONLY)"`
	MaxCandidates           int                   `json:"max_candidates,omitempty" jsonschema:"description=Maximum number of candidates to consider"`
	MaxResults              int                   `json:"max_results,omitempty" jsonschema:"description=Maximum number of results to return"`
	MaxReturnPathResults    int                   `json:"max_return_path_results,omitempty" jsonschema:"description=Maximum number of return path results"`
	MaxSeconds              int                   `json:"max_seconds,omitempty" jsonschema:"description=Maximum seconds per query"`
	MaxOverallSeconds       int                   `json:"max_overall_seconds,omitempty" jsonschema:"description=Maximum overall seconds for all queries"`
	IncludeNetworkFunctions bool                  `json:"include_network_functions,omitempty" jsonschema:"description=Include network functions in results"`
}

// PathSearchQueryArgs represents a single path search query in bulk request
type PathSearchQueryArgs struct {
	From    string `json:"from,omitempty" jsonschema:"description=Source device name"`
	SrcIP   string `json:"src_ip,omitempty" jsonschema:"description=Source IP address or subnet"`
	DstIP   string `json:"dst_ip" jsonschema:"required,description=Destination IP address or subnet"`
	IPProto *int   `json:"ip_proto,omitempty" jsonschema:"description=IP protocol number"`
	SrcPort string `json:"src_port,omitempty" jsonschema:"description=Source port"`
	DstPort string `json:"dst_port,omitempty" jsonschema:"description=Destination port"`
}

func (s *ForwardMCPService) searchPathsBulk(args SearchPathsBulkArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("search_paths_bulk", args, nil)

	// Use defaults if not specified
	networkID := s.getNetworkID(args.NetworkID)
	snapshotID := s.getSnapshotID(args.SnapshotID)

	// Note: snapshotId is optional for bulk API - if omitted, the network's latest processed Snapshot is used
	// We only fetch it if explicitly requested
	if snapshotID == "latest" {
		s.logger.Info("searchPathsBulk - Latest snapshot requested, fetching for network %s", networkID)
		snapshot, err := s.forwardClient.GetLatestSnapshot(networkID)
		if err != nil {
			s.logger.Error("Failed to fetch latest snapshot for network %s: %v", networkID, err)
			return nil, fmt.Errorf("failed to get latest snapshot for network %s: %w", networkID, err)
		}
		if snapshot != nil && snapshot.ID != "" {
			snapshotID = snapshot.ID
			s.logger.Info("searchPathsBulk - Using latest snapshot ID: %s", snapshotID)
		} else {
			s.logger.Warn("No valid snapshot found for network %s", networkID)
			return nil, fmt.Errorf("no valid snapshot found for network %s - ensure the network has been processed", networkID)
		}
	}

	// Validate queries
	if len(args.Queries) == 0 {
		return nil, fmt.Errorf("at least one query must be provided in bulk path search")
	}

	// Convert queries to forward API format
	var bulkQueries []forward.PathSearchParams
	for i, query := range args.Queries {
		// Validate required fields
		if query.DstIP == "" {
			return nil, fmt.Errorf("query %d: dst_ip is required", i+1)
		}

		// Validate that we have either 'from' or 'src_ip'
		if query.From == "" && query.SrcIP == "" {
			return nil, fmt.Errorf("query %d: either 'from' or 'src_ip' must be specified", i+1)
		}

		// When 'from' is specified, srcIp is optional (API will use device as source)
		// When no 'from' is specified, srcIp is required
		srcIP := query.SrcIP
		if query.From == "" && srcIP == "" {
			return nil, fmt.Errorf("query %d: 'src_ip' is required when 'from' is not specified", i+1)
		}

		// Validate dst_ip - must be a valid IP address or CIDR (no device name resolution)
		dstIP := query.DstIP
		s.logger.Debug("Processing dst_ip: %s for query %d", dstIP, i+1)

		// Check if it's a valid IP address
		if net.ParseIP(dstIP) != nil {
			s.logger.Debug("dst_ip '%s' is a valid IP address", dstIP)
		} else if strings.Contains(dstIP, "/") {
			// Check if it's a valid CIDR
			if _, _, err := net.ParseCIDR(dstIP); err != nil {
				return nil, fmt.Errorf("query %d: dst_ip '%s' is not a valid IP address or CIDR: %w", i+1, dstIP, err)
			}
			s.logger.Debug("dst_ip '%s' is a valid CIDR", dstIP)
		} else {
			// Not an IP or CIDR - reject device names
			return nil, fmt.Errorf("query %d: dst_ip '%s' must be a valid IP address or CIDR (device names are not supported)", i+1, dstIP)
		}

		params := forward.PathSearchParams{
			From:    query.From,
			SrcIP:   srcIP,
			DstIP:   dstIP,
			SrcPort: query.SrcPort,
			DstPort: query.DstPort,
		}

		if query.IPProto != nil {
			params.IPProto = query.IPProto
		}

		bulkQueries = append(bulkQueries, params)
	}

	s.logger.Debug("Bulk path search: networkID=%s, snapshotID=%s, queries=%d",
		networkID, snapshotID, len(bulkQueries))

	// Create the bulk request with top-level parameters
	bulkRequest := &forward.PathSearchBulkRequest{
		Queries:                 bulkQueries,
		Intent:                  args.Intent,
		MaxCandidates:           args.MaxCandidates,
		MaxResults:              args.MaxResults,
		MaxReturnPathResults:    args.MaxReturnPathResults,
		MaxSeconds:              args.MaxSeconds,
		MaxOverallSeconds:       args.MaxOverallSeconds,
		IncludeNetworkFunctions: args.IncludeNetworkFunctions,
	}

	// Execute bulk path search
	// Pass empty string if no snapshotId is needed (API will use latest processed snapshot)
	apiSnapshotID := ""
	if snapshotID != "" && snapshotID != "latest" {
		apiSnapshotID = snapshotID
	}
	responses, err := s.forwardClient.SearchPathsBulk(networkID, bulkRequest, apiSnapshotID)
	if err != nil {
		s.logger.Error("Bulk path search failed: %v", err)
		return nil, fmt.Errorf("failed to execute bulk path search: %w", err)
	}

	s.logger.Debug("Bulk path search API returned %d responses", len(responses))
	if len(responses) > 0 {
		s.logger.Debug("First response structure: %+v", responses[0])
	}

	// Track bulk path search in memory system
	if s.apiTracker != nil {
		for i, response := range responses {
			if i < len(args.Queries) {
				query := args.Queries[i]
				// Convert bulk response to legacy format for tracking
				legacyResponse := &forward.PathSearchResponse{
					Paths: make([]forward.Path, len(response.Info.Paths)),
				}
				for j, bulkPath := range response.Info.Paths {
					legacyResponse.Paths[j] = forward.Path{
						Hops: make([]forward.Hop, len(bulkPath.Hops)),
					}
					for k, bulkHop := range bulkPath.Hops {
						legacyResponse.Paths[j].Hops[k] = forward.Hop{
							Device:    bulkHop.DeviceName,
							Interface: bulkHop.IngressInterface,
							Action:    bulkHop.DeviceType,
						}
					}
				}
				if trackErr := s.apiTracker.TrackPathSearch(networkID, query.SrcIP, query.DstIP, legacyResponse); trackErr != nil {
					s.logger.Debug("Failed to track bulk path search %d in memory system: %v", i+1, trackErr)
				}
			}
		}
	}

	// Build summary
	totalPaths := 0
	successfulQueries := 0
	var errors []string

	s.logger.Debug("Processing %d bulk path search responses", len(responses))
	for i, response := range responses {
		// For bulk responses, paths are in response.Info.Paths
		pathCount := len(response.Info.Paths)
		s.logger.Debug("Response %d: Paths=%d, DstIpLocationType=%s, TimedOut=%v",
			i+1, pathCount, response.DstIpLocationType, response.TimedOut)

		if pathCount > 0 {
			totalPaths += pathCount
			successfulQueries++
			s.logger.Debug("Response %d: Found %d paths", i+1, pathCount)
		} else {
			errors = append(errors, fmt.Sprintf("Query %d: No paths found", i+1))
			s.logger.Debug("Response %d: No paths found", i+1)
		}
	}

	// Enhanced response with debugging info
	debugInfo := ""
	if len(errors) > 0 {
		debugInfo += fmt.Sprintf("\n‚ö†Ô∏è  Warnings: %d queries had issues\n", len(errors))
		for _, err := range errors {
			debugInfo += fmt.Sprintf("  - %s\n", err)
		}
	}

	// Check for missing "from" property usage
	missingFromCount := 0
	for _, query := range args.Queries {
		if query.From == "" {
			missingFromCount++
		}
	}
	if missingFromCount > 0 {
		debugInfo += fmt.Sprintf("\nüí° Tip: %d queries don't use the 'from' property. Consider adding it for more accurate results.\n", missingFromCount)
	}

	result := MarshalCompactJSONString(responses)

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Bulk path search completed. %d/%d queries successful, found %d total paths:%s\n%s",
		successfulQueries, len(args.Queries), totalPaths, debugInfo, result))), nil
}

// Helper function to convert service NQEQueryOptions to forward NQEQueryOptions
func (s *ForwardMCPService) convertNQEQueryOptions(options *NQEQueryOptions) *forward.NQEQueryOptions {
	if options == nil {
		return nil
	}

	// Apply default limit if not specified
	limit := options.Limit
	if limit == 0 {
		limit = s.getQueryLimit(0)
	}

	forwardOptions := &forward.NQEQueryOptions{
		Limit:  limit,
		Offset: options.Offset,
		Format: options.Format,
	}

	if options.SortBy != nil {
		forwardOptions.SortBy = make([]forward.NQESortBy, len(options.SortBy))
		for i, sort := range options.SortBy {
			forwardOptions.SortBy[i] = forward.NQESortBy{
				ColumnName: sort.ColumnName,
				Order:      sort.Order,
			}
		}
	}

	if options.Filters != nil {
		forwardOptions.Filters = make([]forward.NQEColumnFilter, len(options.Filters))
		for i, filter := range options.Filters {
			forwardOptions.Filters[i] = forward.NQEColumnFilter{
				ColumnName: filter.ColumnName,
				Value:      filter.Value,
			}
		}
	}

	return forwardOptions
}

// NQE Tool Implementations
func (s *ForwardMCPService) runNQEQueryByID(args RunNQEQueryByIDArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("run_nqe_query_by_id", args, nil)

	// Use defaults if not specified
	networkID := s.getNetworkID(args.NetworkID)
	snapshotID := s.getSnapshotID(args.SnapshotID)

	// Proactive warning for potentially large queries
	if (args.Options == nil || args.Options.Limit == 0 || args.Options.Limit > 1000) && !args.AllResults {
		warnMsg := "‚ö†Ô∏è This query may return a large result set. To avoid hitting API size limits, consider setting 'all_results: true' to fetch results in batches for local analysis, or limit the output with a smaller 'limit' value.\n"
		warnMsg += "Would you like to proceed as is, or update your request?\n"
		warnMsg += "Example: { \"all_results\": true } or { \"options\": { \"limit\": 100 } }\n"
		return mcp.NewToolResponse(mcp.NewTextContent(warnMsg)), nil
	}

	if args.AllResults {
		// Fetch all results in batches using pagination
		limit := s.getQueryLimit(0)
		if args.Options != nil && args.Options.Limit > 0 {
			limit = args.Options.Limit
		}
		offset := 0
		if args.Options != nil && args.Options.Offset > 0 {
			offset = args.Options.Offset
		}

		allItems := []map[string]interface{}{}
		var lastResult *forward.NQERunResult
		for {
			params := &forward.NQEQueryParams{
				NetworkID:  networkID,
				QueryID:    args.QueryID,
				SnapshotID: snapshotID,
				Parameters: args.Parameters,
				Options: &forward.NQEQueryOptions{
					Limit:  limit,
					Offset: offset,
					// Format: "json", // REMOVED: API does not support this field
				},
			}
			result, err := s.forwardClient.RunNQEQueryByID(params)
			if err != nil {
				return nil, fmt.Errorf("failed to run NQE query (batch at offset %d): %w", offset, err)
			}
			if lastResult == nil {
				lastResult = result
			}
			allItems = append(allItems, result.Items...)
			if len(result.Items) < limit {
				break // No more data
			}
			offset += limit
		}
		// Use lastResult as template for metadata, but replace Items
		if lastResult == nil {
			return mcp.NewToolResponse(mcp.NewTextContent("No results found.")), nil
		}
		lastResult.Items = allItems

		// Store in memory system/database with chunking
		var entityID string
		if s.memorySystem != nil {
			id, chunkErr := s.memorySystem.StoreNQEResultWithChunking(args.QueryID, networkID, snapshotID, lastResult, 200)
			if chunkErr != nil {
				s.logger.Warn("Failed to store NQE result with chunking: %v", chunkErr)
			} else {
				s.logger.Debug("Stored NQE result in memory system with chunking (entity: %s)", id)
				entityID = id

				// Automatically build bloom filter for large results
				if s.bloomManager != nil && len(allItems) > 100 {
					filterType := s.determineFilterType(args.QueryID, allItems)
					buildErr := s.bloomManager.BuildFilterFromNQEResult(networkID, filterType, lastResult, 200)
					if buildErr != nil {
						s.logger.Warn("Failed to auto-build bloom filter for large result: %v", buildErr)
					} else {
						s.logger.Info("Auto-built bloom filter for large result - Network: %s, Type: %s, Items: %d", networkID, filterType, len(allItems))
					}
				}
			}
		}

		// Prepare summary
		rowCount := len(allItems)
		var columns []string
		if rowCount > 0 {
			for k := range allItems[0] {
				columns = append(columns, k)
			}
		}
		previewRows := 5
		if rowCount < previewRows {
			previewRows = rowCount
		}
		preview := allItems[:previewRows]
		response := "Fetched all results in batches.\n"
		response += fmt.Sprintf("Total items: %d\nColumns: %v\n", rowCount, columns)
		previewJSON, _ := json.MarshalIndent(preview, "", "  ")
		response += fmt.Sprintf("Preview (first %d rows):\n%s\n", previewRows, string(previewJSON))
		if entityID != "" {
			response += fmt.Sprintf("Stored in memory system as entity: %s\n", entityID)
			response += "You can use get_nqe_result_summary to analyze this result locally.\n"
		}
		return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
	}

	// Single page (default) behavior
	// Validate query ID against database index if available
	stats := s.queryIndex.GetStatistics()
	totalQueries := stats["total_queries"].(int)
	if totalQueries > 0 {
		if entry, err := s.queryIndex.GetQueryByID(args.QueryID); err != nil {
			s.logger.Warn("Query ID %s not found in database index - may be deprecated or invalid", args.QueryID)
			// Continue execution anyway in case it's a newer query not yet in the database
		} else {
			s.logger.Debug("Executing validated query: %s (Path: %s)", entry.QueryID, entry.Path)
		}
	}

	// Create cache key from query parameters
	cacheKey := fmt.Sprintf("query_id:%s|params:%v", args.QueryID, args.Parameters)

	// Try to get result from cache first
	if s.config.Forward.SemanticCache.Enabled && s.semanticCache != nil {
		if cachedResult, found := s.semanticCache.Get(cacheKey, networkID, snapshotID); found {
			s.logger.Debug("Cache hit for NQE query %s", args.QueryID)
			return mcp.NewToolResponse(mcp.NewTextContent(MarshalCompactJSONString(cachedResult))), nil
		}
	}

	params := &forward.NQEQueryParams{
		NetworkID:  networkID,
		QueryID:    args.QueryID,
		SnapshotID: snapshotID,
		Parameters: args.Parameters,
		Options:    s.convertNQEQueryOptions(args.Options),
	}

	// Ensure we have options even if none were provided
	if params.Options == nil {
		params.Options = &forward.NQEQueryOptions{
			Limit: s.getQueryLimit(0),
		}
	}

	// Track execution time for API memory tracking
	start := time.Now()
	result, err := s.forwardClient.RunNQEQueryByID(params)
	executionTime := time.Since(start)

	if err != nil {
		s.logToolCall("run_nqe_query_by_id", args, err)

		// Check for specific NQE query errors and provide helpful messages
		errorStr := err.Error()
		if strings.Contains(errorStr, "Invalid module path") {
			return nil, fmt.Errorf("query contains outdated module imports (this is a data quality issue in the Forward Networks repository) - query ID: %s. Try using find_executable_query to discover alternative queries", args.QueryID)
		}
		if strings.Contains(errorStr, "NQE_RUNTIME_ERROR") {
			return nil, fmt.Errorf("query execution failed due to code issues (this may be a data quality issue) - query ID: %s. Try using find_executable_query to find working alternatives. Error: %w", args.QueryID, err)
		}
		if strings.Contains(errorStr, "result exceeds maximum length") {
			// Automatic fallback to batch mode for large results
			s.logger.Warn("Result too large, retrying with all_results: true for query %s", args.QueryID)
			args.AllResults = true
			// Inform the user that we're retrying in batch mode
			msg := "The result was too large to return directly. Fetching all results in batches for local analysis. A summary will be provided.\n"
			batchResp, batchErr := s.runNQEQueryByID(args)
			if batchErr != nil {
				return nil, batchErr
			}
			// Try to get a summary if possible
			if s.memorySystem != nil && batchResp != nil && len(batchResp.Content) > 0 {
				// Try to extract entity ID from the batch response text
				text := batchResp.Content[0].TextContent.Text
				entityID := ""
				if idx := strings.Index(text, "entity: "); idx != -1 {
					end := strings.Index(text[idx:], "\n")
					if end != -1 {
						entityID = strings.TrimSpace(text[idx+len("entity: ") : idx+end])
					} else {
						entityID = strings.TrimSpace(text[idx+len("entity: "):])
					}
				}
				if entityID != "" {
					summaryArgs := GetNQEResultChunksArgs{EntityID: entityID}
					summaryResp, summaryErr := s.getNQEResultSummary(summaryArgs)
					if summaryErr == nil && summaryResp != nil && len(summaryResp.Content) > 0 {
						msg += "\n" + summaryResp.Content[0].TextContent.Text
					}
				}
			}
			// Prepend our message to the batch response
			if batchResp != nil && len(batchResp.Content) > 0 {
				batchResp.Content[0].TextContent.Text = msg + "\n" + batchResp.Content[0].TextContent.Text
			}
			return batchResp, nil
		}
		if strings.Contains(errorStr, "Provided argument") && strings.Contains(errorStr, "is not a parameter to the given query") {
			// Parameter mismatch error, suggest find_executable_query
			return nil, fmt.Errorf("Query parameter mismatch: %s. Try using find_executable_query to find working alternatives or check the required parameters for this query.", errorStr)
		}
		return nil, fmt.Errorf("failed to run NQE query: %w", err)
	}

	// Track the query execution in memory system
	if s.apiTracker != nil {
		if trackErr := s.apiTracker.TrackNetworkQuery(args.QueryID, networkID, snapshotID, result, executionTime); trackErr != nil {
			s.logger.Debug("Failed to track query execution in memory system: %v", trackErr)
		}
	}

	// Store result in memory system with chunking for LLM/large result use
	if s.memorySystem != nil {
		_, chunkErr := s.memorySystem.StoreNQEResultWithChunking(args.QueryID, networkID, snapshotID, result, 200) // 200 rows per chunk
		if chunkErr != nil {
			s.logger.Warn("Failed to store NQE result with chunking: %v", chunkErr)
		} else {
			s.logger.Debug("Stored NQE result in memory system with chunking (entity: %s)", args.QueryID)
		}
	}

	// Store result in cache for future use
	if s.config.Forward.SemanticCache.Enabled && s.semanticCache != nil {
		if cacheErr := s.semanticCache.Put(cacheKey, networkID, snapshotID, result); cacheErr != nil {
			s.logger.Warn("Failed to cache NQE query result for %s: %v", args.QueryID, cacheErr)
		} else {
			s.logger.Debug("Cached result for NQE query %s (items: %d)", args.QueryID, len(result.Items))
		}
	}

	resultJSON := MarshalCompactJSONString(result)
	s.logger.Debug("NQE query completed with %d items", len(result.Items))

	response := fmt.Sprintf("NQE query completed. Found %d items:\n%s\n\n", len(result.Items), resultJSON)

	// Pagination warning if results may be truncated
	if params.Options != nil && len(result.Items) == params.Options.Limit {
		response += "\n‚ö†Ô∏è Results may be truncated. Use the 'offset' parameter to fetch the next page.\n"
		response += fmt.Sprintf("Example: set 'offset' to %d to get the next page.\n", params.Options.Offset+params.Options.Limit)
		response += "Or set 'all_results: true' in your request to fetch all results in batches.\n"
	}

	// Add helpful suggestions for predefined queries
	response += "Would you like to:\n" +
		"1. Run a different predefined query?\n" +
		"2. Create a custom query?\n" +
		"3. Export these results?"

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

func (s *ForwardMCPService) listNQEQueries(args ListNQEQueriesArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("list_nqe_queries", args, nil)

	// Inline readiness check
	if !s.queryIndex.IsReady() {
		return nil, fmt.Errorf("Query index is not initialized. Try running 'initialize_query_index' tool to manually initialize.")
	}

	// Check if query index is initialized
	stats := s.queryIndex.GetStatistics()
	totalQueries := stats["total_queries"].(int)
	if totalQueries == 0 {
		s.logger.Info("Query index empty, initializing from database...")

		// Try to initialize from database first, then fallback to spec
		if s.database != nil {
			queries, err := s.database.loadWithSmartCachingContext(s.ctx, s.forwardClient, s.logger)
			if err != nil {
				s.logger.Warn("Database loading failed, falling back to spec file: %v", err)
				if err := s.queryIndex.LoadFromSpec(); err != nil {
					return nil, fmt.Errorf("failed to initialize query index: %w", err)
				}
			} else {
				if err := s.queryIndex.LoadFromQueries(queries); err != nil {
					return nil, fmt.Errorf("failed to load queries into index: %w", err)
				}
			}
		} else {
			if err := s.queryIndex.LoadFromSpec(); err != nil {
				return nil, fmt.Errorf("failed to initialize query index: %w", err)
			}
		}
		s.logger.Info("Query index initialized successfully")
	}

	// Use database-backed query index instead of direct API calls
	filteredEntries := s.queryIndex.FilterQueriesByDirectory(args.Directory)

	// Convert NQEQueryIndexEntry to forward.NQEQuery for compatibility
	var queries []forward.NQEQuery
	for _, entry := range filteredEntries {
		queries = append(queries, entry.ConvertToNQEQuery())
	}

	// Format the response with proper JSON structure
	result := MarshalCompactJSONString(queries)

	s.logger.Debug("Found %d valid NQE queries from database index", len(queries))

	// Build a helpful response message
	response := fmt.Sprintf("Found %d NQE queries (from database cache):\n%s\n\n", len(queries), result)

	// Add helpful suggestions based on the results
	if len(queries) == 0 {
		response += "No queries found in the specified directory. Try these common directories:\n" +
			"- /L3/Basic/: Basic network queries\n" +
			"- /L3/Advanced/: Advanced network analysis\n" +
			"- /L3/Security/: Security-related queries\n\n" +
			"Would you like to:\n" +
			"1. Try a different directory?\n" +
			"2. Create a custom query?\n" +
			"3. List all available directories?"
	} else {
		response += "To run a query:\n" +
			"1. Copy the 'queryId' field from the query you want to run\n" +
			"2. Use run_nqe_query_by_id with that queryId\n" +
			"3. Optionally specify limit, offset, or other options\n\n" +
			"Would you like to:\n" +
			"1. Run one of these queries?\n" +
			"2. See more details about a specific query?\n" +
			"3. Try a different directory?"
	}

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// Device Management Tool Implementations
func (s *ForwardMCPService) listDevices(args ListDevicesArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("list_devices", args, nil)

	// Apply default limit if not specified
	limit := args.Limit
	if limit == 0 {
		limit = s.getQueryLimit(0)
	}

	params := &forward.DeviceQueryParams{
		SnapshotID: args.SnapshotID,
		Limit:      limit,
		Offset:     args.Offset,
	}

	response, err := s.forwardClient.GetDevices(args.NetworkID, params)
	if err != nil {
		return nil, fmt.Errorf("failed to list devices: %w", err)
	}

	// Track device discovery in memory system
	if s.apiTracker != nil {
		if trackErr := s.apiTracker.TrackDeviceDiscovery(args.NetworkID, response.Devices); trackErr != nil {
			s.logger.Debug("Failed to track device discovery in memory system: %v", trackErr)
		}
	}

	result := MarshalCompactJSONString(response)
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Found %d devices (total: %d):\n%s", len(response.Devices), response.TotalCount, result))), nil
}

func (s *ForwardMCPService) getDeviceLocations(args GetDeviceLocationsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_device_locations", args, nil)

	// Get all device locations from API
	allLocations, err := s.forwardClient.GetDeviceLocations(args.NetworkID)
	if err != nil {
		return nil, fmt.Errorf("failed to get device locations: %w", err)
	}

	// Apply pagination with safe defaults to prevent token overflow
	limit := args.Limit
	if limit <= 0 {
		limit = 25 // Conservative default limit to prevent token overflow
	}
	if limit > 100 {
		limit = 100 // Cap at 100 to prevent excessive responses
	}
	offset := args.Offset
	if offset < 0 {
		offset = 0
	}

	var locations map[string]string
	var totalCount int
	var hasMore bool

	if args.AllResults {
		// Store all device locations in memory system for large datasets
		locations = allLocations
		totalCount = len(allLocations)
		hasMore = false

		// Store in memory system if available
		if s.memorySystem != nil {
			entity, err := s.memorySystem.CreateEntity("device_locations", "query_result", map[string]interface{}{
				"query_type":  "get_device_locations",
				"network_id":  args.NetworkID,
				"total_count": totalCount,
				"timestamp":   time.Now().Unix(),
			})
			if err == nil {
				// Store the device locations data
				locationsJSON, _ := json.Marshal(locations)
				s.memorySystem.AddObservation(entity.ID, string(locationsJSON), "data", map[string]interface{}{
					"data_type": "device_locations",
					"count":     totalCount,
				})
			}
		}
	} else {
		// Apply pagination to map
		totalCount = len(allLocations)
		start := offset
		end := offset + limit
		if start >= totalCount {
			locations = make(map[string]string)
		} else {
			locations = make(map[string]string)
			keys := make([]string, 0, len(allLocations))
			for k := range allLocations {
				keys = append(keys, k)
			}
			if end > totalCount {
				end = totalCount
			}
			for i := start; i < end; i++ {
				key := keys[i]
				locations[key] = allLocations[key]
			}
		}
		hasMore = offset+len(locations) < totalCount
	}

	// Build response
	var responseText strings.Builder
	responseText.WriteString(fmt.Sprintf("Found %d device locations", totalCount))
	if !args.AllResults {
		responseText.WriteString(fmt.Sprintf(" (showing %d-%d)", offset+1, offset+len(locations)))
		if hasMore {
			responseText.WriteString(fmt.Sprintf(", %d more available", totalCount-offset-len(locations)))
		}
	}
	responseText.WriteString(":\n")

	if len(locations) > 0 {
		result, _ := json.MarshalIndent(locations, "", "  ")
		responseText.WriteString(string(result))
	} else {
		responseText.WriteString("No device locations found.")
	}

	if args.AllResults && s.memorySystem != nil {
		responseText.WriteString(fmt.Sprintf("\n\nüíæ Stored %d device locations in memory system for future reference.", totalCount))
	}

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}

// Snapshot Management Tool Implementations
func (s *ForwardMCPService) listSnapshots(args ListSnapshotsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("list_snapshots", args, nil)

	// Get all snapshots from API
	allSnapshots, err := s.forwardClient.GetSnapshots(args.NetworkID)
	if err != nil {
		return nil, fmt.Errorf("failed to list snapshots: %w", err)
	}

	// Apply pagination with safe defaults to prevent token overflow
	limit := args.Limit
	if limit <= 0 {
		limit = 25 // Conservative default limit to prevent token overflow
	}
	if limit > 100 {
		limit = 100 // Cap at 100 to prevent excessive responses
	}
	offset := args.Offset
	if offset < 0 {
		offset = 0
	}

	var snapshots []forward.Snapshot
	var totalCount int
	var hasMore bool

	if args.AllResults {
		// Store all snapshots in memory system for large datasets
		snapshots = allSnapshots
		totalCount = len(allSnapshots)
		hasMore = false

		// Store in memory system if available
		if s.memorySystem != nil {
			entity, err := s.memorySystem.CreateEntity("snapshot_list", "query_result", map[string]interface{}{
				"query_type":  "list_snapshots",
				"network_id":  args.NetworkID,
				"total_count": totalCount,
				"timestamp":   time.Now().Unix(),
			})
			if err == nil {
				// Store the snapshots data
				snapshotsJSON, _ := json.Marshal(snapshots)
				s.memorySystem.AddObservation(entity.ID, string(snapshotsJSON), "data", map[string]interface{}{
					"data_type": "snapshots_list",
					"count":     totalCount,
				})
			}
		}
	} else {
		// Apply pagination
		totalCount = len(allSnapshots)
		start := offset
		end := offset + limit
		if start >= totalCount {
			snapshots = []forward.Snapshot{}
		} else {
			if end > totalCount {
				end = totalCount
			}
			snapshots = allSnapshots[start:end]
		}
		hasMore = offset+len(snapshots) < totalCount
	}

	// Build response
	var responseText strings.Builder
	responseText.WriteString(fmt.Sprintf("Found %d snapshots", totalCount))
	if !args.AllResults {
		responseText.WriteString(fmt.Sprintf(" (showing %d-%d)", offset+1, offset+len(snapshots)))
		if hasMore {
			responseText.WriteString(fmt.Sprintf(", %d more available", totalCount-offset-len(snapshots)))
		}
		if args.Limit <= 0 {
			responseText.WriteString(" [Note: Using default limit of 25 to prevent token overflow. Use 'limit' parameter to adjust.]")
		}
	}
	responseText.WriteString(":\n")

	if len(snapshots) > 0 {
		result, _ := json.MarshalIndent(snapshots, "", "  ")
		responseText.WriteString(string(result))
	} else {
		responseText.WriteString("No snapshots found.")
	}

	if args.AllResults && s.memorySystem != nil {
		responseText.WriteString(fmt.Sprintf("\n\nüíæ Stored %d snapshots in memory system for future reference.", totalCount))
	}

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}

func (s *ForwardMCPService) getLatestSnapshot(args GetLatestSnapshotArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_latest_snapshot", args, nil)
	snapshot, err := s.forwardClient.GetLatestSnapshot(args.NetworkID)
	if err != nil {
		return nil, fmt.Errorf("failed to get latest snapshot: %w", err)
	}

	result, _ := json.MarshalIndent(snapshot, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Latest snapshot:\n%s", string(result)))), nil
}

// Location Management Tool Implementations
func (s *ForwardMCPService) listLocations(args ListLocationsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("list_locations", args, nil)

	// Get all locations from API
	allLocations, err := s.forwardClient.GetLocations(args.NetworkID)
	if err != nil {
		return nil, fmt.Errorf("failed to list locations: %w", err)
	}

	// Apply pagination with safe defaults to prevent token overflow
	limit := args.Limit
	if limit <= 0 {
		limit = 25 // Conservative default limit to prevent token overflow
	}
	if limit > 100 {
		limit = 100 // Cap at 100 to prevent excessive responses
	}
	offset := args.Offset
	if offset < 0 {
		offset = 0
	}

	var locations []forward.Location
	var totalCount int
	var hasMore bool

	if args.AllResults {
		// Store all locations in memory system for large datasets
		locations = allLocations
		totalCount = len(allLocations)
		hasMore = false

		// Store in memory system if available
		if s.memorySystem != nil {
			entity, err := s.memorySystem.CreateEntity("location_list", "query_result", map[string]interface{}{
				"query_type":  "list_locations",
				"network_id":  args.NetworkID,
				"total_count": totalCount,
				"timestamp":   time.Now().Unix(),
			})
			if err == nil {
				// Store the locations data
				locationsJSON, _ := json.Marshal(locations)
				s.memorySystem.AddObservation(entity.ID, string(locationsJSON), "data", map[string]interface{}{
					"data_type": "locations_list",
					"count":     totalCount,
				})
			}
		}
	} else {
		// Apply pagination
		totalCount = len(allLocations)
		start := offset
		end := offset + limit
		if start >= totalCount {
			locations = []forward.Location{}
		} else {
			if end > totalCount {
				end = totalCount
			}
			locations = allLocations[start:end]
		}
		hasMore = offset+len(locations) < totalCount
	}

	// Build response
	var responseText strings.Builder
	responseText.WriteString(fmt.Sprintf("Found %d locations", totalCount))
	if !args.AllResults {
		responseText.WriteString(fmt.Sprintf(" (showing %d-%d)", offset+1, offset+len(locations)))
		if hasMore {
			responseText.WriteString(fmt.Sprintf(", %d more available", totalCount-offset-len(locations)))
		}
		if args.Limit <= 0 {
			responseText.WriteString(" [Note: Using default limit of 25 to prevent token overflow. Use 'limit' parameter to adjust.]")
		}
	}
	responseText.WriteString(":\n")

	if len(locations) > 0 {
		result, _ := json.MarshalIndent(locations, "", "  ")
		responseText.WriteString(string(result))
	} else {
		responseText.WriteString("No locations found.")
	}

	if args.AllResults && s.memorySystem != nil {
		responseText.WriteString(fmt.Sprintf("\n\nüíæ Stored %d locations in memory system for future reference.", totalCount))
	}

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}

func (s *ForwardMCPService) createLocation(args CreateLocationArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("create_location", args, nil)

	// Log the received parameters for debugging
	s.logger.Info("Creating location with parameters: network_id=%s, name=%s, lat=%f, lng=%f, city=%s, adminDivision=%s, country=%s",
		args.NetworkID, args.Name, args.Lat, args.Lng, args.City, args.AdminDivision, args.Country)

	// Check if lat/lng are zero values (which might indicate they weren't provided)
	if args.Lat == 0 && args.Lng == 0 {
		s.logger.Warn("Latitude and longitude are both zero - this might indicate missing parameters")
	}

	// Validate latitude is within valid range (-90 to +90)
	if args.Lat < -90 || args.Lat > 90 {
		return nil, fmt.Errorf("latitude must be between -90 and +90 degrees, got: %f", args.Lat)
	}

	// Validate longitude is within valid range (-180 to +180)
	if args.Lng < -180 || args.Lng > 180 {
		return nil, fmt.Errorf("longitude must be between -180 and +180 degrees, got: %f", args.Lng)
	}

	location := &forward.LocationCreate{
		ID:            args.ID,
		Name:          args.Name,
		Lat:           args.Lat,
		Lng:           args.Lng,
		City:          args.City,
		AdminDivision: args.AdminDivision,
		Country:       args.Country,
	}

	// Log the location object being sent to the API
	locationJSON, _ := json.Marshal(location)
	s.logger.Info("Sending location to API: %s", string(locationJSON))

	newLocation, err := s.forwardClient.CreateLocation(args.NetworkID, location)
	if err != nil {
		s.logger.Error("Failed to create location: error=%v, network_id=%s", err, args.NetworkID)
		return nil, fmt.Errorf("failed to create location: %w", err)
	}

	result, _ := json.MarshalIndent(newLocation, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Location created successfully:\n%s", string(result)))), nil
}

func (s *ForwardMCPService) createLocationsBulk(args CreateLocationsBulkArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("create_locations_bulk", args, nil)

	if len(args.Locations) == 0 {
		return nil, fmt.Errorf("at least one location must be provided")
	}

	// Validate inputs and transform to forward.LocationBulkPatch slice as required by PATCH
	locations := make([]forward.LocationBulkPatch, 0, len(args.Locations))
	for i, item := range args.Locations {
		// For PATCH: either ID or Name must be provided
		if item.ID == "" && item.Name == "" {
			return nil, fmt.Errorf("location[%d] must have either id (for update) or name (for create)", i)
		}

		// Validate coordinates if provided
		if item.Lat != nil && (*item.Lat < -90 || *item.Lat > 90) {
			return nil, fmt.Errorf("location[%d] latitude must be between -90 and +90 degrees, got: %f", i, *item.Lat)
		}
		if item.Lng != nil && (*item.Lng < -180 || *item.Lng > 180) {
			return nil, fmt.Errorf("location[%d] longitude must be between -180 and +180 degrees, got: %f", i, *item.Lng)
		}

		// Build forward.LocationBulkPatch (PATCH expects partial objects)
		loc := forward.LocationBulkPatch{
			ID:            item.ID,
			Name:          item.Name,
			Lat:           item.Lat,
			Lng:           item.Lng,
			City:          item.City,
			AdminDivision: item.AdminDivision,
			Country:       item.Country,
		}
		locations = append(locations, loc)
	}

	// Execute bulk patch (create/update)
	err := s.forwardClient.CreateLocationsBulk(args.NetworkID, locations)
	if err != nil {
		return nil, fmt.Errorf("failed to patch locations in bulk: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent("Bulk locations patched successfully (204 No Content).")), nil
}

func (s *ForwardMCPService) updateLocation(args UpdateLocationArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("update_location", args, nil)
	update := &forward.LocationUpdate{
		Name:          &args.Name,
		Lat:           args.Lat,
		Lng:           args.Lng,
		City:          &args.City,
		AdminDivision: &args.AdminDivision,
		Country:       &args.Country,
	}

	updatedLocation, err := s.forwardClient.UpdateLocation(args.NetworkID, args.LocationID, update)
	if err != nil {
		return nil, fmt.Errorf("failed to update location: %w", err)
	}

	result, _ := json.MarshalIndent(updatedLocation, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Location updated successfully:\n%s", string(result)))), nil
}

func (s *ForwardMCPService) deleteLocation(args DeleteLocationArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("delete_location", args, nil)
	deletedLocation, err := s.forwardClient.DeleteLocation(args.NetworkID, args.LocationID)
	if err != nil {
		return nil, fmt.Errorf("failed to delete location: %w", err)
	}

	result, _ := json.MarshalIndent(deletedLocation, "", "  ")
	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Location deleted successfully:\n%s", string(result)))), nil
}

func (s *ForwardMCPService) deleteSnapshot(args DeleteSnapshotArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("delete_snapshot", args, nil)
	err := s.forwardClient.DeleteSnapshot(args.SnapshotID)
	if err != nil {
		return nil, fmt.Errorf("failed to delete snapshot: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Snapshot %s deleted successfully", args.SnapshotID))), nil
}

// isCloudDevice checks if a device name suggests it's a cloud device
func (s *ForwardMCPService) isCloudDevice(deviceName string) bool {
	deviceNameLower := strings.ToLower(deviceName)

	// Debug logging for troubleshooting
	// fmt.Printf("DEBUG: Checking device '%s' (lowercase: '%s')\n", deviceName, deviceNameLower)

	// Explicit cloud device patterns (exact matches or specific patterns)
	exactCloudPatterns := []string{
		"csr1kv", "csr-1kv", "csr_1kv",
		"pan-fw", "pan_fw", "panfw",
		"aws-", "azure-", "gcp-",
		"virtual-", "vm-", "container-",
	}

	// Check for exact cloud device patterns
	for _, pattern := range exactCloudPatterns {
		if strings.Contains(deviceNameLower, pattern) {
			return true
		}
	}

	// Check for cloud-specific naming patterns (more restrictive)
	cloudPatterns := []string{
		"aws-", "azure-", "gcp-", "cloud-", // Cloud provider prefixes
		"virtual-", "vm-", "container-", // Virtualization prefixes
		"-aws", "-azure", "-gcp", // Cloud provider suffixes (but not -cloud)
		"-virtual", "-vm", "-container", // Virtualization suffixes
	}

	for _, pattern := range cloudPatterns {
		if strings.Contains(deviceNameLower, pattern) {
			return true
		}
	}

	// Check for standalone cloud keywords (but not as part of infrastructure names)
	// This is more restrictive - only match if the keyword appears in a cloud context
	// Note: "cloud" and "kvm" are handled separately below
	standaloneCloudKeywords := []string{
		"aws", "azure", "gcp", "virtual", "vm", "container",
	}

	for _, keyword := range standaloneCloudKeywords {
		// Only match if the keyword appears as a standalone word or with cloud-specific prefixes
		if strings.Contains(deviceNameLower, keyword) {
			// Check if it's part of a cloud-specific pattern
			if strings.HasPrefix(deviceNameLower, keyword+"-") ||
				strings.HasSuffix(deviceNameLower, "-"+keyword) ||
				strings.Contains(deviceNameLower, "-"+keyword+"-") {
				return true
			}
		}
	}

	// Special case: "cloud" keyword - only match if it's clearly a cloud device
	// Don't match infrastructure devices that happen to contain "cloud" in their name
	if strings.Contains(deviceNameLower, "cloud") {
		// Only match if it's a clear cloud device pattern
		cloudSpecificPatterns := []string{
			"cloud-", "-cloud-", // Cloud prefixes and middle patterns
			"aws-cloud", "azure-cloud", "gcp-cloud",
			"cloud-aws", "cloud-azure", "cloud-gcp",
		}

		for _, pattern := range cloudSpecificPatterns {
			if strings.Contains(deviceNameLower, pattern) {
				return true
			}
		}

		// Don't match infrastructure devices like "fel-wps1-cloud2s02" or "fel-wps1-cloudm3s01"
		// These are physical devices with "cloud" in their infrastructure role name
		return false
	}

	// Special case: "kvm" keyword - only match if it's clearly a virtual device
	// Don't match physical KVM devices like "fel-wps1-kvmd2s01"
	if strings.Contains(deviceNameLower, "kvm") {
		// Only match if it's a clear virtual device pattern
		kvmVirtualPatterns := []string{
			"kvm-", "-kvm-", // KVM prefixes and middle patterns
			"virtual-kvm", "vm-kvm", "container-kvm",
			"kvm-virtual", "kvm-vm", "kvm-container",
		}

		for _, pattern := range kvmVirtualPatterns {
			if strings.Contains(deviceNameLower, pattern) {
				return true
			}
		}

		// Don't match physical KVM devices like "fel-wps1-kvmd2s01"
		// These are physical devices with "kvm" in their infrastructure role name
		// Only match if it's clearly a virtual device (not just ending with -kvm)
		return false
	}

	return false
}

func (s *ForwardMCPService) updateDeviceLocations(args UpdateDeviceLocationsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("update_device_locations", args, nil)

	// Log the devices being moved for debugging
	s.logger.Info("Updating device locations for %d devices: %v", len(args.Locations), args.Locations)

	// Pre-validate for cloud devices
	var cloudDevices []string
	var physicalDevices = make(map[string]string)

	for deviceName, locationID := range args.Locations {
		if s.isCloudDevice(deviceName) {
			cloudDevices = append(cloudDevices, deviceName)
			s.logger.Warn("Detected cloud device in location update: %s", deviceName)
		} else {
			physicalDevices[deviceName] = locationID
		}
	}

	// If we found cloud devices, provide a helpful warning
	if len(cloudDevices) > 0 {
		s.logger.Warn("Cloud devices detected: %v. These will be excluded from the location update.", cloudDevices)

		// If all devices are cloud devices, return an error
		if len(physicalDevices) == 0 {
			return nil, fmt.Errorf("all devices are cloud devices and cannot be moved to physical locations: %v\n\nNote: Cloud devices (CSR1KV, PAN-FW, etc.) cannot be moved to physical locations. Please use only physical devices for location assignments.", cloudDevices)
		}

		// Update only physical devices
		args.Locations = physicalDevices
		s.logger.Info("Proceeding with %d physical devices, excluding %d cloud devices", len(physicalDevices), len(cloudDevices))
	}

	err := s.forwardClient.UpdateDeviceLocations(args.NetworkID, args.Locations)
	if err != nil {
		// Check if this is a cloud device error
		if strings.Contains(err.Error(), "Unrecognized devices cannot be moved") {
			// Extract device names from the error message
			errorMsg := err.Error()
			s.logger.Warn("Cloud devices detected in location update request: %s", errorMsg)

			// Provide a more helpful error message
			return nil, fmt.Errorf("failed to update device locations: %w\n\nNote: Cloud devices (like CSR1KV, PAN-FW, etc.) cannot be moved to physical locations. Please exclude cloud devices from the location assignment.", err)
		}

		s.logger.Error("Failed to update device locations: error=%v, network_id=%s", err, args.NetworkID)
		return nil, fmt.Errorf("failed to update device locations: %w", err)
	}

	// Build success message
	successMsg := fmt.Sprintf("Updated locations for %d devices", len(args.Locations))
	if len(cloudDevices) > 0 {
		successMsg += fmt.Sprintf("\nNote: %d cloud devices were excluded: %v", len(cloudDevices), cloudDevices)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(successMsg)), nil
}

// resolveNetworkIDByName resolves a network name to its networkId using a case-insensitive match.
func (s *ForwardMCPService) resolveNetworkIDByName(name string) (string, error) {
	networks, err := s.forwardClient.GetNetworks()
	if err != nil {
		return "", err
	}
	var matches []forward.Network
	for _, n := range networks {
		if strings.EqualFold(n.Name, name) {
			matches = append(matches, n)
		}
	}
	if len(matches) == 1 {
		return matches[0].ID, nil
	} else if len(matches) > 1 {
		return "", fmt.Errorf("multiple networks found with the name '%s'", name)
	}
	return "", fmt.Errorf("no network found with the name '%s'", name)
}

// First-Class Query Tool Implementations - Critical Network Operations
// These wrap the most important predefined queries as dedicated tools

func (s *ForwardMCPService) getDeviceBasicInfo(args GetDeviceBasicInfoArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_device_basic_info", args, nil)

	queryArgs := RunNQEQueryByIDArgs{
		NetworkID:  args.NetworkID,
		SnapshotID: args.SnapshotID,
		QueryID:    "FQ_ac651cb2901b067fe7dbfb511613ab44776d8029", // Device Basic Info
		Options:    args.Options,
	}

	return s.runNQEQueryByID(queryArgs)
}

func (s *ForwardMCPService) getDeviceHardware(args GetDeviceHardwareArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_device_hardware", args, nil)

	queryArgs := RunNQEQueryByIDArgs{
		NetworkID:  args.NetworkID,
		SnapshotID: args.SnapshotID,
		QueryID:    "FQ_7ec4a8148b48a91271f342c512b2af1cdb276744", // Device Hardware
		Options:    args.Options,
	}

	return s.runNQEQueryByID(queryArgs)
}

func (s *ForwardMCPService) getHardwareSupport(args GetHardwareSupportArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_hardware_support", args, nil)

	queryArgs := RunNQEQueryByIDArgs{
		NetworkID:  args.NetworkID,
		SnapshotID: args.SnapshotID,
		QueryID:    "FQ_f0984b777b940b4376ed3ec4317ad47437426e7c", // Hardware Support
		Options:    args.Options,
	}

	return s.runNQEQueryByID(queryArgs)
}

func (s *ForwardMCPService) getOSSupport(args GetOSSupportArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_os_support", args, nil)

	queryArgs := RunNQEQueryByIDArgs{
		NetworkID:  args.NetworkID,
		SnapshotID: args.SnapshotID,
		QueryID:    "FQ_fc33d9fd70ba19a18455b0e4d26ca8420003d9cc", // OS Support
		Options:    args.Options,
	}

	return s.runNQEQueryByID(queryArgs)
}

func (s *ForwardMCPService) searchConfigs(args SearchConfigsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("search_configs", args, nil)

	queryArgs := RunNQEQueryByIDArgs{
		NetworkID:  args.NetworkID,
		SnapshotID: args.SnapshotID,
		QueryID:    "FQ_e636c47826ad7144f09eaf6bc14dfb0b560e7cc9", // Config Search
		Parameters: map[string]interface{}{
			"searchPattern": args.SearchTerm,
		},
		Options: args.Options,
	}

	return s.runNQEQueryByID(queryArgs)
}

func (s *ForwardMCPService) getConfigDiff(args GetConfigDiffArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_config_diff", args, nil)

	params := map[string]interface{}{}
	if args.AfterSnapshot != "" {
		params["compareSnapshotId"] = args.AfterSnapshot
	}

	queryArgs := RunNQEQueryByIDArgs{
		NetworkID:  args.NetworkID,
		SnapshotID: args.BeforeSnapshot,
		QueryID:    "FQ_51f090cbea069b4049eb283716ab3bbb3f578aea", // Config Diff
		Parameters: params,
		Options:    args.Options,
	}

	return s.runNQEQueryByID(queryArgs)
}

// Default Settings Management Tool Implementations

func (s *ForwardMCPService) getDefaultSettings(args GetDefaultSettingsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_default_settings", args, nil)

	// Get network name if possible
	networkName := "Not set"
	if s.defaults.NetworkID != "" {
		networks, err := s.forwardClient.GetNetworks()
		if err == nil {
			for _, network := range networks {
				if network.ID == s.defaults.NetworkID {
					networkName = fmt.Sprintf("%s (%s)", network.Name, network.ID)
					break
				}
			}
		}
	}

	settings := map[string]interface{}{
		"default_network_id":   s.defaults.NetworkID,
		"default_network_name": networkName,
		"default_snapshot_id":  s.defaults.SnapshotID,
		"default_query_limit":  s.defaults.QueryLimit,
		"environment_source":   "Loaded from environment variables and config files",
	}

	result := MarshalCompactJSONString(settings)

	response := fmt.Sprintf("Current default settings:\n%s\n\n", result)
	response += "To change defaults:\n"
	response += "‚Ä¢ Use set_default_network to change the default network\n"
	response += "‚Ä¢ Update environment variables (FORWARD_DEFAULT_NETWORK_ID, etc.)\n"
	response += "‚Ä¢ Modify your .env file or config.json\n\n"

	if s.defaults.NetworkID == "" {
		response += " No default network is set. Consider setting FORWARD_DEFAULT_NETWORK_ID in your environment."
	}

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

func (s *ForwardMCPService) setDefaultNetwork(args SetDefaultNetworkArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("set_default_network", args, nil)

	var networkID string
	var networkName string

	// Try to resolve the network identifier (could be ID or name)
	if args.NetworkIdentifier == "" {
		return mcp.NewToolResponse(mcp.NewTextContent("Please provide either a network ID or network name.")), nil
	}

	// First, try as network ID by listing networks and checking if it exists
	networks, err := s.forwardClient.GetNetworks()
	if err != nil {
		return nil, fmt.Errorf("failed to get networks: %w", err)
	}

	// Check if it's a direct network ID match
	for _, network := range networks {
		if network.ID == args.NetworkIdentifier {
			networkID = network.ID
			networkName = network.Name
			break
		}
	}

	// If not found as ID, try to resolve as name
	if networkID == "" {
		resolvedID, err := s.resolveNetworkIDByName(args.NetworkIdentifier)
		if err != nil {
			// List available networks for user reference
			availableNetworks := "Available networks:\n"
			for i, network := range networks {
				availableNetworks += fmt.Sprintf("%d. %s (ID: %s)\n", i+1, network.Name, network.ID)
			}

			return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Network '%s' not found.\n\n%s\nPlease use either a valid network ID or exact network name.", args.NetworkIdentifier, availableNetworks))), nil
		}

		networkID = resolvedID
		// Find the network name
		for _, network := range networks {
			if network.ID == networkID {
				networkName = network.Name
				break
			}
		}
	}

	// Update the default (for this session)
	s.defaults.NetworkID = networkID

	response := "Default network updated successfully!\n\n"
	response += fmt.Sprintf("New default: %s (ID: %s)\n\n", networkName, networkID)
	response += "This change applies to the current session. To make it permanent:\n"
	response += fmt.Sprintf("‚Ä¢ Set FORWARD_DEFAULT_NETWORK_ID=%s in your environment\n", networkID)
	response += "‚Ä¢ Or update your .env file or config.json\n\n"
	response += "All subsequent tool calls will now use this network by default when network_id is not specified."

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// Semantic Cache and AI Enhancement Tool Implementations

// getCacheStats returns semantic cache performance statistics
func (s *ForwardMCPService) getCacheStats(args GetCacheStatsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_cache_stats", args, nil)

	stats := s.semanticCache.GetStats()

	statsJSON := MarshalCompactJSONString(stats)

	summary := fmt.Sprintf("Semantic Cache Performance Statistics:\n%s\n\nCache Summary:\n", statsJSON)
	summary += fmt.Sprintf("‚Ä¢ Total Queries: %v\n", stats["total_queries"])
	summary += fmt.Sprintf("‚Ä¢ Hit Rate: %v\n", stats["hit_rate_percent"])
	summary += fmt.Sprintf("‚Ä¢ Active Entries: %v/%v\n", stats["total_entries"], stats["max_entries"])
	summary += fmt.Sprintf("‚Ä¢ Similarity Threshold: %v\n", stats["threshold"])

	return mcp.NewToolResponse(mcp.NewTextContent(summary)), nil
}

// suggestSimilarQueries provides intelligent query suggestions based on cache history
func (s *ForwardMCPService) suggestSimilarQueries(args SuggestSimilarQueriesArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("suggest_similar_queries", args, nil)

	if args.Query == "" {
		return nil, fmt.Errorf("query parameter is required")
	}

	limit := args.Limit
	if limit <= 0 {
		limit = 5
	}

	similarQueries, err := s.semanticCache.FindSimilarQueries(args.Query, limit)
	if err != nil {
		return nil, fmt.Errorf("failed to find similar queries: %w", err)
	}

	if len(similarQueries) == 0 {
		return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("No similar queries found for: '%s'\n\nTry running some NQE queries first to build up the cache.", args.Query))), nil
	}

	response := fmt.Sprintf("Similar queries found for: '%s'\n\n", args.Query)
	for i, entry := range similarQueries {
		response += fmt.Sprintf("%d. (%.1f%% similarity) %s\n", i+1, entry.SimilarityScore*100, entry.Query)
		if entry.NetworkID != "" {
			response += fmt.Sprintf("   Network: %s", entry.NetworkID)
			if entry.SnapshotID != "" {
				response += fmt.Sprintf(", Snapshot: %s", entry.SnapshotID)
			}
			response += "\n"
		}
		response += fmt.Sprintf("   Used %d times, last accessed: %s\n\n", entry.AccessCount, entry.LastAccessed.Format("2006-01-02 15:04:05"))
	}

	response += "You can use these suggestions to refine your query or explore related network analysis patterns."

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// clearCache removes expired or all cache entries
func (s *ForwardMCPService) clearCache(args ClearCacheArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("clear_cache", args, nil)

	var removed int
	var operation string

	if args.ClearAll {
		// For simplicity, we'll implement a full clear by creating a new cache
		// In production, you might want a more sophisticated approach
		stats := s.semanticCache.GetStats()
		totalEntries := stats["total_entries"].(int)

		// Reinitialize the cache
		var embeddingService EmbeddingService
		if s.config.Forward.SemanticCache.EmbeddingProvider == "openai" {
			if openaiKey := os.Getenv("OPENAI_API_KEY"); openaiKey != "" {
				embeddingService = NewOpenAIEmbeddingService(openaiKey)
			} else {
				embeddingService = NewMockEmbeddingService()
			}
		} else if s.config.Forward.SemanticCache.EmbeddingProvider == "keyword" {
			embeddingService = NewKeywordEmbeddingService()
		} else {
			embeddingService = NewMockEmbeddingService()
		}
		s.semanticCache = NewSemanticCache(embeddingService, s.logger, s.instanceID, &s.config.Forward.SemanticCache)

		removed = totalEntries
		operation = "Cleared all cache entries"
	} else {
		removed = s.semanticCache.ClearExpired()
		operation = "Cleared expired cache entries"
	}

	response := fmt.Sprintf("%s: %d entries removed\n\n", operation, removed)

	// Show updated stats
	newStats := s.semanticCache.GetStats()
	response += "Updated cache status:\n"
	response += fmt.Sprintf("‚Ä¢ Active entries: %v\n", newStats["total_entries"])
	response += fmt.Sprintf("‚Ä¢ Hit rate: %v\n", newStats["hit_rate_percent"])

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// AI-Powered Query Discovery Tool Implementations

// searchNQEQueries performs AI-powered search through the NQE query library
func (s *ForwardMCPService) searchNQEQueries(args SearchNQEQueriesArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("search_nqe_queries", args, nil)

	// Inline readiness check
	if !s.queryIndex.IsReady() {
		return nil, fmt.Errorf("Query index is not initialized. Try running 'initialize_query_index' tool to manually initialize.")
	}

	if args.Query == "" {
		return mcp.NewToolResponse(mcp.NewTextContent("Please provide a search query describing what you want to analyze (e.g., 'AWS security vulnerabilities', 'BGP routing issues', 'interface statistics')")), nil
	}

	// Set default limit
	limit := args.Limit
	if limit <= 0 {
		limit = 10
	}

	// Initialize query index if needed
	stats := s.queryIndex.GetStatistics()
	totalQueries := stats["total_queries"].(int)
	if totalQueries == 0 {
		s.logger.Info("Query index empty, initializing...")
		if err := s.queryIndex.LoadFromSpec(); err != nil {
			return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Failed to initialize query index: %v\n\n**Manual Fix:** Run this command:\n```json\n{\"tool\": \"initialize_query_index\", \"arguments\": {\"generate_embeddings\": false}}\n```", err))), nil
		}
		s.logger.Info("Query index initialized successfully")
	}

	// Use semantic search if embeddings are available, otherwise fallback to keyword search
	results, err := s.queryIndex.SearchQueries(args.Query, limit)
	if err != nil {
		return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Search failed: %v", err))), nil
	}

	// Apply category/subcategory filters if specified
	var filteredResults []*QuerySearchResult
	categoryFilterApplied := args.Category != ""
	subcategoryFilterApplied := args.Subcategory != ""

	for _, result := range results {
		if categoryFilterApplied && !strings.EqualFold(result.Category, args.Category) {
			continue
		}
		if subcategoryFilterApplied && !strings.EqualFold(result.Subcategory, args.Subcategory) {
			continue
		}
		filteredResults = append(filteredResults, result)
	}

	if len(filteredResults) == 0 {
		return mcp.NewToolResponse(mcp.NewTextContent("No relevant NQE queries found for your search. Try different keywords or check your query index.")), nil
	}

	// Format the response
	response := fmt.Sprintf("%s search found %d relevant NQE queries for: '%s'\n\n",
		filteredResults[0].MatchType, len(filteredResults), args.Query)
	for i, result := range filteredResults {
		if i >= limit {
			break
		}
		response += fmt.Sprintf("**%d. %s** (%.1f%% match)\n   **Intent:** %s\n   **Description:** %s\n   **Category:** %s\n   **Query ID:** `%s`\n\n",
			i+1, result.Path, result.SimilarityScore*100, result.Intent, result.Description, result.Category, result.QueryID)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// initializeQueryIndex builds or rebuilds the AI-powered query index
func (s *ForwardMCPService) initializeQueryIndex(args InitializeQueryIndexArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("initialize_query_index", args, nil)

	response := "üîß Initializing AI-powered NQE query index...\n\n"

	// Prefer database data over spec file if available
	var queries []forward.NQEQueryDetail
	var dataSource string

	if s.database != nil {
		response += "üìä Checking database for query data...\n"
		dbQueries, err := s.database.LoadQueries()
		if err != nil {
			response += fmt.Sprintf("‚ö†Ô∏è  Database load failed: %v\n", err)
		} else if len(dbQueries) > 0 {
			queries = dbQueries
			dataSource = "database"
			response += fmt.Sprintf("‚úÖ Found %d queries in database (includes enhanced metadata)\n", len(queries))

			// Count queries with enhanced metadata
			enhancedCount := 0
			for _, q := range dbQueries {
				if q.SourceCode != "" || q.Description != "" {
					enhancedCount++
				}
			}
			if enhancedCount > 0 {
				response += fmt.Sprintf("üöÄ %d queries have enhanced metadata (source code/descriptions)\n", enhancedCount)
			}
		} else {
			response += "üì≠ Database is empty\n"
		}
	}

	// Fallback to spec file if no database data
	if len(queries) == 0 {
		response += "üìñ Loading from spec file as fallback...\n"

		// Check if spec file exists using robust path resolution
		specPath, err := findSpecFile("NQELibrary.json")
		if err != nil {
			return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("No database data available and NQE spec file not found. Error: %v\n\nüí° **Solutions:**\n‚Ä¢ Run 'hydrate_database' to load queries from API\n‚Ä¢ Ensure the spec file exists in the 'spec' directory\n‚Ä¢ Check that the MCP server is running from the correct directory", err))), nil
		}

		response += fmt.Sprintf("üìÅ Found spec file at: %s\n", specPath)

		if err := s.queryIndex.LoadFromSpec(); err != nil {
			return nil, fmt.Errorf("failed to load query index from spec: %w", err)
		}
		dataSource = "spec file"
	} else {
		// Load database queries into index
		if err := s.queryIndex.LoadFromQueries(queries); err != nil {
			return nil, fmt.Errorf("failed to load database queries into index: %w", err)
		}
	}

	stats := s.queryIndex.GetStatistics()
	totalQueries := stats["total_queries"].(int)
	embeddedQueries := stats["embedded_queries"].(int)

	response += fmt.Sprintf("‚úÖ Loaded %d NQE queries successfully from %s\n", totalQueries, dataSource)

	if embeddedQueries > 0 {
		coverage := stats["embedding_coverage"].(float64)
		response += fmt.Sprintf("Found %d cached embeddings (%.1f%% coverage) for offline AI search\n", embeddedQueries, coverage*100)
	}
	response += "\n"

	// Generate embeddings if requested
	if args.GenerateEmbeddings {
		if _, ok := s.queryIndex.embeddingService.(*MockEmbeddingService); ok {
			response += "Cannot generate embeddings: OpenAI API key not configured\n"
			response += "Set OPENAI_API_KEY environment variable to enable embedding generation\n"
			response += "Current functionality limited to keyword-based search\n\n"
		} else {
			response += "Generating AI embeddings for semantic search...\n"
			response += "   This will take several minutes for thousands of queries\n"
			response += "   Embeddings will be cached for offline use\n\n"

			if err := s.queryIndex.GenerateEmbeddings(); err != nil {
				if strings.Contains(err.Error(), "cannot generate real embeddings") {
					response += "Embedding generation failed: OpenAI API key required\n"
					response += "   Set FORWARD_EMBEDDING_PROVIDER=keyword for basic functionality\n\n"
				} else {
					return nil, fmt.Errorf("failed to generate embeddings: %w", err)
				}
			} else {
				updatedStats := s.queryIndex.GetStatistics()
				newEmbeddedCount := updatedStats["embedded_queries"].(int)
				newCoverage := updatedStats["embedding_coverage"].(float64)

				response += fmt.Sprintf("Generated and cached %d embeddings (%.1f%% coverage)\n", newEmbeddedCount, newCoverage*100)
				response += "Embeddings saved to spec/nqe-embeddings.json for offline use\n\n"
			}
		}
	}

	// Show final statistics
	finalStats := s.queryIndex.GetStatistics()
	response += "üìä **Query Index Status:**\n"
	response += fmt.Sprintf("‚Ä¢ Total queries: %d\n", finalStats["total_queries"].(int))

	if categories, ok := finalStats["categories"].(map[string]int); ok {
		response += "‚Ä¢ Categories:\n"
		categoryCount := 0
		for category, count := range categories {
			if category != "" && categoryCount < 5 { // Show top 5 categories
				response += fmt.Sprintf("  - %s: %d queries\n", category, count)
				categoryCount++
			}
		}
		if len(categories) > 5 {
			response += fmt.Sprintf("  - ... and %d more categories\n", len(categories)-5)
		}
	}

	finalEmbedded := finalStats["embedded_queries"].(int)
	if finalEmbedded > 0 {
		finalCoverage := finalStats["embedding_coverage"].(float64)
		response += fmt.Sprintf("‚Ä¢ AI embeddings: %d queries (%.1f%% coverage) üß†\n", finalEmbedded, finalCoverage*100)
		response += "  ‚Üí Full semantic search available\n"
	} else {
		response += "‚Ä¢ AI embeddings: None available\n"
		response += "  ‚Üí Using keyword-based search fallback\n"
	}

	response += "\n**Query index ready!**\n"
	if finalEmbedded > 0 {
		response += "Use `search_nqe_queries` for AI-powered semantic search\n"
		response += "Works offline with cached embeddings (no OpenAI API calls needed)\n"
	} else {
		response += "Use `search_nqe_queries` for keyword-based search\n"
		response += "Generate embeddings with OpenAI for better semantic matching\n"
	}

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// hydrateDatabase hydrates the database by loading queries from the Forward Networks API
func (s *ForwardMCPService) hydrateDatabase(args HydrateDatabaseArgs) (*mcp.ToolResponse, error) {
	if s.database == nil {
		return nil, fmt.Errorf("database is not available")
	}

	// Set defaults
	if args.MaxRetries == 0 {
		args.MaxRetries = 3
	}

	s.logger.Info("üîÑ Starting database hydration (async mode)...")

	// Check if we need to force refresh or if database is empty
	existingQueries, err := s.database.LoadQueries()
	if err != nil {
		s.logger.Warn("üîÑ Failed to load existing queries: %v", err)
		existingQueries = []forward.NQEQueryDetail{}
	}

	if len(existingQueries) > 0 && !args.ForceRefresh {
		return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Database already contains %d queries. Use force_refresh=true to refresh anyway.", len(existingQueries)))), nil
	}

	// Run hydration in background
	go func() {
		ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
		defer cancel()
		var queries []forward.NQEQueryDetail
		var err error
		if args.EnhancedMode {
			existingCommitIDs := make(map[string]string)
			for _, query := range existingQueries {
				if query.LastCommit.ID != "" {
					existingCommitIDs[query.Path] = query.LastCommit.ID
				}
			}
			queries, err = s.forwardClient.GetNQEAllQueriesEnhancedWithCacheContext(ctx, existingCommitIDs)
			if err != nil {
				s.logger.Warn("üîÑ Enhanced API failed, falling back to basic API: %v", err)
				queries, err = s.database.loadFromBasicAPI(s.forwardClient, s.logger)
			}
		} else {
			queries, err = s.database.loadFromBasicAPI(s.forwardClient, s.logger)
		}
		if err != nil {
			s.logger.Error("failed to load queries from API: %v", err)
			return
		}
		if !args.ForceRefresh && len(existingQueries) > 0 {
			queries = s.database.mergeQueries(existingQueries, queries)
		}
		if err := s.database.SaveQueries(queries); err != nil {
			s.logger.Error("failed to save queries to database: %v", err)
			return
		}
		if err := s.database.SetMetadata("last_sync", time.Now().Format(time.RFC3339)); err != nil {
			s.logger.Warn("üîÑ Failed to update sync time: %v", err)
		}
		s.logger.Info("üîÑ Database hydration completed with %d queries", len(queries))
		s.logger.Info("üîÑ Refreshing query index after hydration...")
		if s.queryIndex != nil {
			if err := s.queryIndex.LoadFromQueries(queries); err != nil {
				s.logger.Warn("üîÑ Failed to refresh query index: %v", err)
			} else {
				s.logger.Info("üîÑ Query index refreshed with %d queries", len(queries))
				stats := s.queryIndex.GetStatistics()
				embeddedCount := stats["embedded_queries"].(int)
				if embeddedCount > 0 && embeddedCount < len(queries) {
					s.logger.Info("üß† Consider regenerating embeddings to include new queries in semantic search")
				}
			}
		}
		if s.queryIndex != nil && args.RegenerateEmbeddings {
			s.logger.Info("üß† Regenerating AI embeddings after hydration...")
			if _, ok := s.queryIndex.embeddingService.(*MockEmbeddingService); ok {
				s.logger.Warn("‚ö†Ô∏è  Cannot generate embeddings: OpenAI API key not configured")
			} else {
				if err := s.queryIndex.GenerateEmbeddings(); err != nil {
					s.logger.Warn("üß† Failed to regenerate embeddings: %v", err)
				} else {
					updatedStats := s.queryIndex.GetStatistics()
					newEmbeddedCount := updatedStats["embedded_queries"].(int)
					newCoverage := updatedStats["embedding_coverage"].(float64)
					s.logger.Info("üß† Successfully regenerated %d embeddings (%.1f%% coverage)", newEmbeddedCount, newCoverage*100)
				}
			}
		}
		// Optionally: log completion
		s.logger.Info("Database hydration background process complete.")
	}()

	return mcp.NewToolResponse(mcp.NewTextContent("Database hydration has started in the background. This process may take several minutes. You can continue using other tools, or check the status with get_database_status. Once hydration is complete, the query index will be refreshed automatically.")), nil
}

// refreshQueryIndex refreshes the query index from the current database content
func (s *ForwardMCPService) refreshQueryIndex(args RefreshQueryIndexArgs) (*mcp.ToolResponse, error) {
	if s.database == nil {
		return nil, fmt.Errorf("database is not available")
	}

	if s.queryIndex == nil {
		return nil, fmt.Errorf("query index is not available")
	}

	s.logger.Info("üîÑ Refreshing query index from database...")

	// Load queries from database
	queries, err := s.database.LoadQueries()
	if err != nil {
		return nil, fmt.Errorf("failed to load queries from database: %w", err)
	}

	if len(queries) == 0 {
		return mcp.NewToolResponse(mcp.NewTextContent("No queries found in database. Use hydrate_database to load queries first.")), nil
	}

	// Load queries into index
	if err := s.queryIndex.LoadFromQueries(queries); err != nil {
		return nil, fmt.Errorf("failed to load queries into index: %w", err)
	}

	s.logger.Info("üîÑ Query index refreshed with %d queries", len(queries))

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Query index refreshed successfully with %d queries.", len(queries)))), nil
}

// getDatabaseStatus returns the current status of the database and query index
func (s *ForwardMCPService) getDatabaseStatus(args GetDatabaseStatusArgs) (*mcp.ToolResponse, error) {
	status := map[string]interface{}{
		"database_available":    s.database != nil,
		"query_index_available": s.queryIndex != nil,
		"timestamp":             time.Now().Format(time.RFC3339),
	}

	if s.database != nil {
		// Get database stats
		queries, err := s.database.LoadQueries()
		if err != nil {
			status["database_error"] = err.Error()
			status["query_count"] = 0
		} else {
			status["query_count"] = len(queries)
		}

		// Get last sync time
		if lastSync, err := s.database.GetMetadata("last_sync"); err == nil {
			status["last_sync"] = lastSync
		}

		// Get database path
		status["database_path"] = s.database.dbPath
	}

	if s.queryIndex != nil {
		// Get query index stats
		status["query_index_empty"] = !s.queryIndex.IsReady()
		status["query_index_loading"] = s.queryIndex.IsLoading()

		// Get index stats if available
		indexStats := s.queryIndex.GetStatistics()
		if indexStats != nil {
			status["index_stats"] = indexStats
		}
	}

	// Marshal to JSON for pretty output
	statusJSON, err := json.MarshalIndent(status, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal status: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(string(statusJSON))), nil
}

// Memory Management Tool Implementations

// createEntity creates a new entity in the knowledge graph
func (s *ForwardMCPService) createEntity(args CreateEntityArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	entity, err := s.memorySystem.CreateEntity(args.Name, args.Type, args.Metadata)
	if err != nil {
		return nil, fmt.Errorf("failed to create entity: %w", err)
	}

	entityJSON, err := json.MarshalIndent(entity, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal entity: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Entity created successfully:\n%s", string(entityJSON)))), nil
}

// createRelation creates a relation between two entities
func (s *ForwardMCPService) createRelation(args CreateRelationArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	relation, err := s.memorySystem.CreateRelation(args.FromID, args.ToID, args.Type, args.Properties)
	if err != nil {
		return nil, fmt.Errorf("failed to create relation: %w", err)
	}

	relationJSON, err := json.MarshalIndent(relation, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal relation: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Relation created successfully:\n%s", string(relationJSON)))), nil
}

// addObservation adds an observation to an entity
func (s *ForwardMCPService) addObservation(args AddObservationArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	observation, err := s.memorySystem.AddObservation(args.EntityID, args.Content, args.Type, args.Metadata)
	if err != nil {
		return nil, fmt.Errorf("failed to add observation: %w", err)
	}

	observationJSON, err := json.MarshalIndent(observation, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal observation: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Observation added successfully:\n%s", string(observationJSON)))), nil
}

// searchEntities searches for entities in the knowledge graph with automatic bloom filter optimization
func (s *ForwardMCPService) searchEntities(args SearchEntitiesArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	// Check if we have bloom filters available for NQE result entities
	if args.EntityType == "nqe_result" && s.bloomManager != nil {
		// Try to use bloom filter for faster searching
		networkID := s.getNetworkID("")
		if networkID != "" {
			// Check if we have any bloom filters for this network
			stats := s.bloomManager.GetFilterStats()
			for filterKey, metadata := range stats {
				if strings.Contains(filterKey, networkID) {
					// We have a bloom filter, use it for searching
					s.logger.Debug("Using bloom filter for entity search: %s", filterKey)

					// Extract search terms from the query
					searchTerms := s.extractSearchTerms(args.Query)
					if len(searchTerms) > 0 {
						// Use bloom filter search
						filterType := metadata.FilterType
						searchResult, err := s.bloomManager.SearchFilter(networkID, filterType, searchTerms, nil)
						if err == nil && searchResult.MatchedCount > 0 {
							// Bloom filter found matches, now get the actual entities
							entities, err := s.memorySystem.SearchEntities(args.Query, args.EntityType, args.Limit)
							if err != nil {
								return nil, fmt.Errorf("failed to search entities after bloom filter: %w", err)
							}

							response := fmt.Sprintf("üîç Bloom filter search completed in %v!\n", searchResult.SearchTime)
							response += fmt.Sprintf("üìä Found %d potential matches (bloom filter)\n", searchResult.MatchedCount)
							response += fmt.Sprintf("üìã Retrieved %d entities:\n", len(entities))

							entitiesJSON, err := json.MarshalIndent(entities, "", "  ")
							if err != nil {
								return nil, fmt.Errorf("failed to marshal entities: %w", err)
							}
							response += string(entitiesJSON)

							return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
						}
					}
				}
			}
		}
	}

	// Fallback to regular search
	entities, err := s.memorySystem.SearchEntities(args.Query, args.EntityType, args.Limit)
	if err != nil {
		return nil, fmt.Errorf("failed to search entities: %w", err)
	}

	if len(entities) == 0 {
		return mcp.NewToolResponse(mcp.NewTextContent("No entities found matching the search criteria.")), nil
	}

	entitiesJSON, err := json.MarshalIndent(entities, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal entities: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Found %d entities:\n%s", len(entities), string(entitiesJSON)))), nil
}

// getEntity retrieves a specific entity by ID or name
func (s *ForwardMCPService) getEntity(args GetEntityArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	entity, err := s.memorySystem.GetEntity(args.Identifier)
	if err != nil {
		return nil, fmt.Errorf("failed to get entity: %w", err)
	}

	entityJSON, err := json.MarshalIndent(entity, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal entity: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Entity found:\n%s", string(entityJSON)))), nil
}

// getRelations retrieves relations for an entity
func (s *ForwardMCPService) getRelations(args GetRelationsArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	// Get all relations from memory system
	allRelations, err := s.memorySystem.GetRelations(args.EntityID, args.RelationType)
	if err != nil {
		return nil, fmt.Errorf("failed to get relations: %w", err)
	}

	// Apply pagination with safe defaults to prevent token overflow
	limit := args.Limit
	if limit <= 0 {
		limit = 25 // Conservative default limit to prevent token overflow
	}
	if limit > 100 {
		limit = 100 // Cap at 100 to prevent excessive responses
	}
	offset := args.Offset
	if offset < 0 {
		offset = 0
	}

	var relations []*Relation
	var totalCount int
	var hasMore bool

	if args.AllResults {
		// Store all relations in memory system for large datasets
		relations = allRelations
		totalCount = len(allRelations)
		hasMore = false

		// Store in memory system if available
		entity, err := s.memorySystem.CreateEntity("relations_list", "query_result", map[string]interface{}{
			"query_type":    "get_relations",
			"entity_id":     args.EntityID,
			"relation_type": args.RelationType,
			"total_count":   totalCount,
			"timestamp":     time.Now().Unix(),
		})
		if err == nil {
			// Store the relations data
			relationsJSON, _ := json.Marshal(relations)
			s.memorySystem.AddObservation(entity.ID, string(relationsJSON), "data", map[string]interface{}{
				"data_type": "relations_list",
				"count":     totalCount,
			})
		}
	} else {
		// Apply pagination
		totalCount = len(allRelations)
		start := offset
		end := offset + limit
		if start >= totalCount {
			relations = []*Relation{}
		} else {
			if end > totalCount {
				end = totalCount
			}
			relations = allRelations[start:end]
		}
		hasMore = offset+len(relations) < totalCount
	}

	// Build response
	var responseText strings.Builder
	if totalCount == 0 {
		responseText.WriteString("No relations found for this entity.")
	} else {
		responseText.WriteString(fmt.Sprintf("Found %d relations", totalCount))
		if !args.AllResults {
			responseText.WriteString(fmt.Sprintf(" (showing %d-%d)", offset+1, offset+len(relations)))
			if hasMore {
				responseText.WriteString(fmt.Sprintf(", %d more available", totalCount-offset-len(relations)))
			}
		}
		responseText.WriteString(":\n")

		if len(relations) > 0 {
			relationsJSON, err := json.MarshalIndent(relations, "", "  ")
			if err != nil {
				return nil, fmt.Errorf("failed to marshal relations: %w", err)
			}
			responseText.WriteString(string(relationsJSON))
		}
	}

	if args.AllResults && s.memorySystem != nil {
		responseText.WriteString(fmt.Sprintf("\n\nüíæ Stored %d relations in memory system for future reference.", totalCount))
	}

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}

// getObservations retrieves observations for an entity
func (s *ForwardMCPService) getObservations(args GetObservationsArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	// Get all observations from memory system
	allObservations, err := s.memorySystem.GetObservations(args.EntityID, args.ObservationType)
	if err != nil {
		return nil, fmt.Errorf("failed to get observations: %w", err)
	}

	// Apply pagination with safe defaults to prevent token overflow
	limit := args.Limit
	if limit <= 0 {
		limit = 25 // Conservative default limit to prevent token overflow
	}
	if limit > 100 {
		limit = 100 // Cap at 100 to prevent excessive responses
	}
	offset := args.Offset
	if offset < 0 {
		offset = 0
	}

	var observations []*Observation
	var totalCount int
	var hasMore bool

	if args.AllResults {
		// Store all observations in memory system for large datasets
		observations = allObservations
		totalCount = len(allObservations)
		hasMore = false

		// Store in memory system if available
		entity, err := s.memorySystem.CreateEntity("observations_list", "query_result", map[string]interface{}{
			"query_type":       "get_observations",
			"entity_id":        args.EntityID,
			"observation_type": args.ObservationType,
			"total_count":      totalCount,
			"timestamp":        time.Now().Unix(),
		})
		if err == nil {
			// Store the observations data
			observationsJSON, _ := json.Marshal(observations)
			s.memorySystem.AddObservation(entity.ID, string(observationsJSON), "data", map[string]interface{}{
				"data_type": "observations_list",
				"count":     totalCount,
			})
		}
	} else {
		// Apply pagination
		totalCount = len(allObservations)
		start := offset
		end := offset + limit
		if start >= totalCount {
			observations = []*Observation{}
		} else {
			if end > totalCount {
				end = totalCount
			}
			observations = allObservations[start:end]
		}
		hasMore = offset+len(observations) < totalCount
	}

	// Build response
	var responseText strings.Builder
	if totalCount == 0 {
		responseText.WriteString("No observations found for this entity.")
	} else {
		responseText.WriteString(fmt.Sprintf("Found %d observations", totalCount))
		if !args.AllResults {
			responseText.WriteString(fmt.Sprintf(" (showing %d-%d)", offset+1, offset+len(observations)))
			if hasMore {
				responseText.WriteString(fmt.Sprintf(", %d more available", totalCount-offset-len(observations)))
			}
		}
		responseText.WriteString(":\n")

		if len(observations) > 0 {
			observationsJSON, err := json.MarshalIndent(observations, "", "  ")
			if err != nil {
				return nil, fmt.Errorf("failed to marshal observations: %w", err)
			}
			responseText.WriteString(string(observationsJSON))
		}
	}

	if args.AllResults && s.memorySystem != nil {
		responseText.WriteString(fmt.Sprintf("\n\nüíæ Stored %d observations in memory system for future reference.", totalCount))
	}

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}

// deleteEntity deletes an entity and all its relations and observations
func (s *ForwardMCPService) deleteEntity(args DeleteEntityArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	// Get entity details before deletion for confirmation
	entity, err := s.memorySystem.GetEntity(args.EntityID)
	if err != nil {
		return nil, fmt.Errorf("entity not found: %w", err)
	}

	err = s.memorySystem.DeleteEntity(args.EntityID)
	if err != nil {
		return nil, fmt.Errorf("failed to delete entity: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Entity '%s' (%s) deleted successfully, including all its relations and observations.", entity.Name, entity.Type))), nil
}

// deleteRelation deletes a specific relation
func (s *ForwardMCPService) deleteRelation(args DeleteRelationArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	err := s.memorySystem.DeleteRelation(args.RelationID)
	if err != nil {
		return nil, fmt.Errorf("failed to delete relation: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Relation '%s' deleted successfully.", args.RelationID))), nil
}

// deleteObservation deletes a specific observation
func (s *ForwardMCPService) deleteObservation(args DeleteObservationArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	err := s.memorySystem.DeleteObservation(args.ObservationID)
	if err != nil {
		return nil, fmt.Errorf("failed to delete observation: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Observation '%s' deleted successfully.", args.ObservationID))), nil
}

// getMemoryStats returns statistics about the memory system
func (s *ForwardMCPService) getMemoryStats(args GetMemoryStatsArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	stats, err := s.memorySystem.GetMemoryStats()
	if err != nil {
		return nil, fmt.Errorf("failed to get memory stats: %w", err)
	}

	statsJSON, err := json.MarshalIndent(stats, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal stats: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Memory system statistics:\n%s", string(statsJSON)))), nil
}

// getQueryAnalytics gets analytics about query patterns for a network
func (s *ForwardMCPService) getQueryAnalytics(args GetQueryAnalyticsArgs) (*mcp.ToolResponse, error) {
	if s.apiTracker == nil {
		return nil, fmt.Errorf("API memory tracker is not available")
	}

	analytics, err := s.apiTracker.GetQueryAnalytics(args.NetworkID)
	if err != nil {
		return nil, fmt.Errorf("failed to get query analytics: %w", err)
	}

	analyticsJSON, err := json.MarshalIndent(analytics, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal analytics: %w", err)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(fmt.Sprintf("Query analytics for network %s:\n%s", args.NetworkID, string(analyticsJSON)))), nil
}

// getNQEResultChunks retrieves chunked NQE query results from the memory system
func (s *ForwardMCPService) getNQEResultChunks(args GetNQEResultChunksArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	entityID := args.EntityID
	// If entity_id is not provided, try to look up by query_id/network_id/snapshot_id
	if entityID == "" && args.QueryID != "" && args.NetworkID != "" && args.SnapshotID != "" {
		lookupName := fmt.Sprintf("%s-%s-%s", args.QueryID, args.NetworkID, args.SnapshotID)
		entity, err := s.memorySystem.getEntityByName(lookupName)
		if err != nil {
			return nil, fmt.Errorf("could not find result entity for query/network/snapshot: %w", err)
		}
		entityID = entity.ID
	}

	if entityID == "" {
		return nil, fmt.Errorf("must provide either entity_id or (query_id, network_id, snapshot_id)")
	}

	chunks, err := s.memorySystem.GetNQEResultChunks(entityID)
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve result chunks: %w", err)
	}

	// If chunk_index is provided, return only that chunk
	if args.ChunkIndex != nil {
		idx := *args.ChunkIndex
		if idx < 0 || idx >= len(chunks) {
			return nil, fmt.Errorf("chunk_index %d out of range (total chunks: %d)", idx, len(chunks))
		}
		return mcp.NewToolResponse(mcp.NewTextContent(chunks[idx])), nil
	}

	// Otherwise, return all chunks as a JSON array
	chunksJSON, _ := json.Marshal(chunks)
	return mcp.NewToolResponse(mcp.NewTextContent(string(chunksJSON))), nil
}

// Add get_nqe_result_summary tool handler
// Arguments: entity_id OR (query_id, network_id, snapshot_id)
func (s *ForwardMCPService) getNQEResultSummary(args GetNQEResultChunksArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}
	entityID := args.EntityID
	if entityID == "" && args.QueryID != "" && args.NetworkID != "" && args.SnapshotID != "" {
		lookupName := fmt.Sprintf("%s-%s-%s", args.QueryID, args.NetworkID, args.SnapshotID)
		entity, err := s.memorySystem.getEntityByName(lookupName)
		if err != nil {
			return nil, fmt.Errorf("could not find result entity for query/network/snapshot: %w", err)
		}
		entityID = entity.ID
	}
	if entityID == "" {
		return nil, fmt.Errorf("must provide either entity_id or (query_id, network_id, snapshot_id)")
	}
	// Get summary observation
	obs, err := s.memorySystem.GetObservations(entityID, "nqe_result_summary")
	if err != nil || len(obs) == 0 {
		return nil, fmt.Errorf("no summary found for entity %s", entityID)
	}

	response := fmt.Sprintf("NQE result summary for entity %s:\n%s", entityID, obs[0].Content)

	// Check if bloom filter is available for this data
	if s.bloomManager != nil {
		networkID := s.getNetworkID(args.NetworkID)
		if networkID != "" {
			stats := s.bloomManager.GetFilterStats()
			for filterKey, metadata := range stats {
				if strings.Contains(filterKey, networkID) {
					response += fmt.Sprintf("\n\nüîç Bloom Filter Available!\n")
					response += fmt.Sprintf("- Filter Type: %s\n", metadata.FilterType)
					response += fmt.Sprintf("- Items Indexed: %d\n", metadata.ItemCount)
					response += fmt.Sprintf("- Memory Usage: %s\n", formatBytes(metadata.MemoryUsage))
					response += fmt.Sprintf("- Last Updated: %v\n", metadata.LastUpdated)
					response += fmt.Sprintf("\nüí° Use search_bloom_filter for sub-millisecond searches!")
					break
				}
			}
		}
	}

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// Add analyze_nqe_result_sql tool handler
type AnalyzeNQEResultSQLArgs struct {
	EntityID string `json:"entity_id" jsonschema:"required,description=Entity ID containing the NQE results to analyze"`
	SQLQuery string `json:"sql_query" jsonschema:"required,description=SQL query to execute against the NQE results"`
}

func (s *ForwardMCPService) analyzeNQEResultSQL(args AnalyzeNQEResultSQLArgs) (*mcp.ToolResponse, error) {
	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}
	if args.EntityID == "" || args.SQLQuery == "" {
		return nil, fmt.Errorf("entity_id and sql_query are required")
	}
	// Get all chunks for the entity
	chunks, err := s.memorySystem.GetNQEResultChunks(args.EntityID)
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve result chunks: %w", err)
	}
	if len(chunks) == 0 {
		return nil, fmt.Errorf("no data found for entity %s", args.EntityID)
	}
	// Parse all rows from all chunks
	var allRows []map[string]interface{}
	for _, chunk := range chunks {
		var rows []map[string]interface{}
		if err := json.Unmarshal([]byte(chunk), &rows); err != nil {
			return nil, fmt.Errorf("failed to unmarshal chunk: %w", err)
		}
		allRows = append(allRows, rows...)
	}
	if len(allRows) == 0 {
		return nil, fmt.Errorf("no rows found for entity %s", args.EntityID)
	}
	// Create in-memory SQLite DB
	db, err := sql.Open("sqlite3", ":memory:")
	if err != nil {
		return nil, fmt.Errorf("failed to create in-memory sqlite db: %w", err)
	}
	defer db.Close()
	// Infer columns from first row
	firstRow := allRows[0]
	var columns []string
	for k := range firstRow {
		columns = append(columns, k)
	}
	// Create table
	tableCols := ""
	for i, col := range columns {
		if i > 0 {
			tableCols += ", "
		}
		tableCols += fmt.Sprintf("%s TEXT", col)
	}
	tableName := "nqe_result"
	createStmt := fmt.Sprintf("CREATE TABLE %s (%s);", tableName, tableCols)
	_, err = db.Exec(createStmt)
	if err != nil {
		return nil, fmt.Errorf("failed to create table: %w", err)
	}
	// Insert rows
	insertStmt := fmt.Sprintf("INSERT INTO %s (%s) VALUES (%s)", tableName, strings.Join(columns, ", "), strings.TrimRight(strings.Repeat("?,", len(columns)), ","))
	for _, row := range allRows {
		vals := make([]interface{}, len(columns))
		for i, col := range columns {
			if v, ok := row[col]; ok {
				vals[i] = fmt.Sprintf("%v", v)
			} else {
				vals[i] = nil
			}
		}
		_, err := db.Exec(insertStmt, vals...)
		if err != nil {
			return nil, fmt.Errorf("failed to insert row: %w", err)
		}
	}
	// Run the query (limit to 100 rows)
	query := args.SQLQuery
	if !strings.Contains(strings.ToLower(query), "limit") {
		query += " LIMIT 100"
	}
	rows, err := db.Query(query)
	if err != nil {
		return nil, fmt.Errorf("SQL query error: %w", err)
	}
	defer rows.Close()
	// Read results
	resultRows := []map[string]interface{}{}
	cols, _ := rows.Columns()
	for rows.Next() {
		vals := make([]interface{}, len(cols))
		valPtrs := make([]interface{}, len(cols))
		for i := range vals {
			valPtrs[i] = &vals[i]
		}
		if err := rows.Scan(valPtrs...); err != nil {
			return nil, fmt.Errorf("failed to scan row: %w", err)
		}
		rowMap := map[string]interface{}{}
		for i, col := range cols {
			rowMap[col] = vals[i]
		}
		resultRows = append(resultRows, rowMap)
	}
	resultJSON, _ := json.MarshalIndent(resultRows, "", "  ")
	response := fmt.Sprintf("SQL query result (%d rows, max 100 shown):\n%s", len(resultRows), string(resultJSON))
	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// buildBloomFilter builds a bloom filter from NQE query results
func (s *ForwardMCPService) buildBloomFilter(args BuildBloomFilterArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("build_bloom_filter", args, nil)

	if s.bloomManager == nil {
		return nil, fmt.Errorf("bloom search manager is not available")
	}

	// Use defaults if not specified
	networkID := s.getNetworkID(args.NetworkID)
	chunkSize := args.ChunkSize
	if chunkSize <= 0 {
		chunkSize = 200 // Default chunk size
	}

	// Run the NQE query to get data for building the filter
	params := &forward.NQEQueryParams{
		NetworkID:  networkID,
		QueryID:    args.QueryID,
		SnapshotID: s.getSnapshotID(""),
		Options: &forward.NQEQueryOptions{
			Limit: 1000, // Reasonable limit for filter building
		},
	}

	result, err := s.forwardClient.RunNQEQueryByID(params)
	if err != nil {
		return nil, fmt.Errorf("failed to run NQE query for filter building: %w", err)
	}

	if len(result.Items) == 0 {
		return nil, fmt.Errorf("no data found for building bloom filter")
	}

	// Build the bloom filter
	err = s.bloomManager.BuildFilterFromNQEResult(networkID, args.FilterType, result, chunkSize)
	if err != nil {
		return nil, fmt.Errorf("failed to build bloom filter: %w", err)
	}

	// Get filter stats
	stats := s.bloomManager.GetFilterStats()
	filterKey := fmt.Sprintf("%s-%s", networkID, args.FilterType)
	metadata := stats[filterKey]

	response := fmt.Sprintf("‚úÖ Bloom filter built successfully!\n\n"+
		"**Filter Details:**\n"+
		"- Network ID: %s\n"+
		"- Filter Type: %s\n"+
		"- Items Processed: %d\n"+
		"- Memory Usage: %d bytes\n"+
		"- False Positive Rate: %.2f%%\n"+
		"- Chunks: %d\n\n"+
		"**Next Steps:**\n"+
		"Use `search_bloom_filter` to efficiently search this dataset with sub-millisecond performance.",
		networkID, args.FilterType, metadata.ItemCount, metadata.MemoryUsage,
		metadata.FalsePositiveRate*100, metadata.ChunkCount)

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// searchBloomFilter searches a bloom filter for matching items
func (s *ForwardMCPService) searchBloomFilter(args SearchBloomFilterArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("search_bloom_filter", args, nil)

	if s.bloomManager == nil {
		return nil, fmt.Errorf("bloom search manager is not available")
	}

	if s.memorySystem == nil {
		return nil, fmt.Errorf("memory system is not available")
	}

	// Use defaults if not specified
	networkID := s.getNetworkID(args.NetworkID)

	// Check if filter exists
	if !s.bloomManager.IsFilterAvailable(networkID, args.FilterType) {
		return nil, fmt.Errorf("no bloom filter found for %s (network: %s). Use build_bloom_filter first.", args.FilterType, networkID)
	}

	// Get the full dataset from memory system
	chunks, err := s.memorySystem.GetNQEResultChunks(args.EntityID)
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve result chunks: %w", err)
	}

	if len(chunks) == 0 {
		return nil, fmt.Errorf("no data found for entity %s", args.EntityID)
	}

	// Parse all rows from all chunks
	var allItems []map[string]interface{}
	for _, chunk := range chunks {
		var rows []map[string]interface{}
		if err := json.Unmarshal([]byte(chunk), &rows); err != nil {
			return nil, fmt.Errorf("failed to unmarshal chunk: %w", err)
		}
		allItems = append(allItems, rows...)
	}

	// Search the bloom filter
	searchResult, err := s.bloomManager.SearchFilter(networkID, args.FilterType, args.SearchTerms, allItems)
	if err != nil {
		return nil, fmt.Errorf("failed to search bloom filter: %w", err)
	}

	// Format response
	response := fmt.Sprintf("üîç Bloom Search Results\n\n"+
		"**Search Performance:**\n"+
		"- Search Time: %v\n"+
		"- Total Items: %d\n"+
		"- Matched Items: %d\n"+
		"- Search Terms: %v\n\n"+
		"**Filter Stats:**\n"+
		"- Network ID: %s\n"+
		"- Filter Type: %s\n"+
		"- Memory Usage: %d bytes\n"+
		"- False Positive Rate: %.2f%%\n\n"+
		"**Matched Items (%d):**\n",
		searchResult.SearchTime, searchResult.TotalItems, searchResult.MatchedCount,
		args.SearchTerms, searchResult.FilterStats.NetworkID, searchResult.FilterStats.FilterType,
		searchResult.FilterStats.MemoryUsage, searchResult.FilterStats.FalsePositiveRate*100,
		len(searchResult.MatchedItems))

	// Add matched items (limit to first 10 for display)
	displayLimit := 10
	if len(searchResult.MatchedItems) < displayLimit {
		displayLimit = len(searchResult.MatchedItems)
	}

	for i := 0; i < displayLimit; i++ {
		itemJSON, _ := json.MarshalIndent(searchResult.MatchedItems[i], "", "  ")
		response += fmt.Sprintf("%d. %s\n", i+1, string(itemJSON))
	}

	if len(searchResult.MatchedItems) > displayLimit {
		response += fmt.Sprintf("\n... and %d more items (use analyze_nqe_result_sql for full analysis)\n",
			len(searchResult.MatchedItems)-displayLimit)
	}

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// getBloomFilterStats returns statistics for all bloom filters
func (s *ForwardMCPService) getBloomFilterStats(args GetBloomFilterStatsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("get_bloom_filter_stats", args, nil)

	if s.bloomManager == nil {
		return nil, fmt.Errorf("bloom search manager is not available")
	}

	stats := s.bloomManager.GetFilterStats()
	totalMemory := s.bloomManager.GetMemoryUsage()

	if len(stats) == 0 {
		return mcp.NewToolResponse(mcp.NewTextContent("No bloom filters found. Use `build_bloom_filter` to create filters for efficient searching.")), nil
	}

	response := fmt.Sprintf("üìä Bloom Filter Statistics\n\n"+
		"**Overall Stats:**\n"+
		"- Total Filters: %d\n"+
		"- Total Memory Usage: %d bytes (%.2f MB)\n\n"+
		"**Filter Details:**\n",
		len(stats), totalMemory, float64(totalMemory)/(1024*1024))

	for key, metadata := range stats {
		response += fmt.Sprintf("**%s**\n"+
			"- Network ID: %s\n"+
			"- Filter Type: %s\n"+
			"- Items: %d\n"+
			"- Memory: %d bytes\n"+
			"- False Positive Rate: %.2f%%\n"+
			"- Last Updated: %s\n"+
			"- Chunks: %d\n\n",
			key, metadata.NetworkID, metadata.FilterType, metadata.ItemCount,
			metadata.MemoryUsage, metadata.FalsePositiveRate*100,
			metadata.LastUpdated.Format("2006-01-02 15:04:05"), metadata.ChunkCount)
	}

	response += "**Performance Benefits:**\n" +
		"- Sub-millisecond search performance\n" +
		"- Memory-efficient filtering\n" +
		"- Reduced API calls for large datasets\n" +
		"- Pre-filtering before SQL analysis"

	return mcp.NewToolResponse(mcp.NewTextContent(response)), nil
}

// determineFilterType determines the appropriate filter type based on query ID and data content
func (s *ForwardMCPService) determineFilterType(queryID string, items []map[string]interface{}) string {
	// Check query ID patterns first
	if strings.Contains(queryID, "device") || strings.Contains(queryID, "devices") {
		return "device"
	}
	if strings.Contains(queryID, "interface") || strings.Contains(queryID, "interfaces") {
		return "interface"
	}
	if strings.Contains(queryID, "config") || strings.Contains(queryID, "configuration") {
		return "config"
	}
	if strings.Contains(queryID, "route") || strings.Contains(queryID, "routing") {
		return "route"
	}
	if strings.Contains(queryID, "vlan") {
		return "vlan"
	}
	if strings.Contains(queryID, "acl") || strings.Contains(queryID, "firewall") {
		return "security"
	}

	// Fallback: analyze the actual data structure
	if len(items) > 0 {
		item := items[0]
		if _, hasDevice := item["device_name"]; hasDevice {
			return "device"
		}
		if _, hasInterface := item["interface_name"]; hasInterface {
			return "interface"
		}
		if _, hasConfig := item["configuration"]; hasConfig {
			return "config"
		}
	}

	// Default to generic type
	return "data"
}

// extractSearchTerms extracts meaningful search terms from a query string
func (s *ForwardMCPService) extractSearchTerms(query string) []string {
	if query == "" {
		return nil
	}

	// Split by common delimiters and clean up
	terms := strings.FieldsFunc(query, func(r rune) bool {
		return r == ' ' || r == ',' || r == ';' || r == '|' || r == '&'
	})

	var cleanTerms []string
	for _, term := range terms {
		// Remove common stop words and short terms
		term = strings.TrimSpace(term)
		if len(term) > 2 && !s.isStopWord(term) {
			cleanTerms = append(cleanTerms, strings.ToLower(term))
		}
	}

	return cleanTerms
}

// isStopWord checks if a word is a common stop word
func (s *ForwardMCPService) isStopWord(word string) bool {
	stopWords := map[string]bool{
		"the": true, "and": true, "or": true, "but": true, "in": true, "on": true, "at": true,
		"to": true, "for": true, "of": true, "with": true, "by": true, "is": true, "are": true,
		"was": true, "were": true, "be": true, "been": true, "have": true, "has": true, "had": true,
		"do": true, "does": true, "did": true, "will": true, "would": true, "could": true, "should": true,
		"a": true, "an": true, "this": true, "that": true, "these": true, "those": true,
		"all": true, "any": true, "some": true, "no": true, "not": true, "only": true, "just": true,
	}
	return stopWords[strings.ToLower(word)]
}

// formatBytes formats bytes into human-readable format
func formatBytes(bytes int64) string {
	const unit = 1024
	if bytes < unit {
		return fmt.Sprintf("%d B", bytes)
	}
	div, exp := int64(unit), 0
	for n := bytes / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(bytes)/float64(div), "KMGTPE"[exp])
}

func (s *ForwardMCPService) pathSearchWorkflow(args PathSearchWorkflowArgs) (*mcp.ToolResponse, error) {
	sessionID := fmt.Sprintf("path_session_%v", args.SessionID)
	state := s.workflowManager.GetState(sessionID)

	switch state.CurrentStep {
	case "start":
		return s.startPathSearchWorkflow(sessionID)
	case "explain_best_practices":
		return s.explainPathSearchBestPractices(sessionID)
	case "show_bulk_example":
		return s.showBulkPathSearchExample(sessionID)
	case "guide_request_building":
		return s.guidePathSearchRequestBuilding(sessionID)
	case "network_scope_discovery":
		return s.guideNetworkScopeDiscovery(sessionID)
	default:
		return s.startPathSearchWorkflow(sessionID)
	}
}

func (s *ForwardMCPService) startPathSearchWorkflow(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "explain_best_practices",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üöÄ **Welcome to the Path Search Workflow!**

This workflow will guide you through effective path search using Forward Networks best practices.

**Key Principles:**
1. **Always use 'from' property** - Specify the source device for more accurate results
2. **Use bulk operations** - For multiple paths, use search_paths_bulk for better performance
3. **Set appropriate limits** - Control response size with max_results and max_candidates
4. **Choose the right intent** - PREFER_DELIVERED, PREFER_VIOLATIONS, or VIOLATIONS_ONLY

**Next Steps:**
- Learn about best practices for path search
- See examples of bulk path search requests
- Get guidance on building effective requests

Would you like to continue with the best practices explanation?`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) explainPathSearchBestPractices(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "show_bulk_example",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üìã **Path Search Best Practices**

**1. Use the 'from' Property (CRITICAL)**
- Always specify the source device using 'from' property
- This provides more accurate results than src_ip alone
- Example: "from": "router-01", "src_ip": "10.0.1.1"

**2. Choose the Right Tool**
- **Single path**: Use search_paths for one-off analysis
- **Multiple paths**: Use search_paths_bulk for concurrent execution

**3. Set Appropriate Intent**
- PREFER_DELIVERED: Find paths where traffic reaches destination
- PREFER_VIOLATIONS: Find paths with drops, blackholes, loops
- VIOLATIONS_ONLY: Only find problematic paths

**4. Control Response Size**
- max_results: Limit returned paths (default: 1)
- max_candidates: Limit computed candidates (default: 5000)
- max_seconds: Per-query timeout (default: 30s)

**5. Performance Tips**
- Use bulk operations for multiple queries
- Set reasonable timeouts
- Include network functions only when needed

Would you like to see a bulk path search example?`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) showBulkPathSearchExample(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "guide_request_building",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üí° **Bulk Path Search Example**

Here's how to structure a bulk path search request:

{
  "network_id": "your-network-id",
  "queries": [
    {
      "from": "router-01",
      "src_ip": "10.0.1.1",
      "dst_ip": "10.0.2.1",
      "src_port": "80",
      "dst_port": "443"
    },
    {
      "from": "switch-01", 
      "src_ip": "10.0.1.2",
      "dst_ip": "10.0.3.1"
    },
    {
      "from": "firewall-01",
      "src_ip": "192.168.1.1",
      "dst_ip": "8.8.8.8"
    }
  ],
  "intent": "PREFER_DELIVERED",
  "max_results": 5,
  "max_candidates": 1000,
  "max_seconds": 30
}

**Key Points:**
- Each query in the array uses the 'from' property
- All queries run concurrently for better performance
- Common parameters (intent, limits) apply to all queries
- Individual queries can override common parameters

Would you like guidance on building your own requests?`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) guidePathSearchRequestBuilding(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "network_scope_discovery",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üéØ **Building Effective Path Search Requests**

**Step 1: Choose Your Tool**
- Single path: search_paths
- Multiple paths: search_paths_bulk

**Step 2: Gather Required Information**
- Network ID (use list_networks to find)
- Source device name (use list_devices to find)
- Source IP address
- Destination IP address/subnet

**Step 3: Build Your Request**
{
  "network_id": "your-network-id",
  "from": "device-name",           // ALWAYS include this
  "src_ip": "source-ip",           // Combine with 'from'
  "dst_ip": "destination-ip",      // Required
  "intent": "PREFER_DELIVERED",    // Choose appropriate intent
  "max_results": 5                 // Control response size
}

**Step 4: For Bulk Requests**
- Create an array of queries
- Each query follows the same structure
- Set common parameters at the top level

**Common Mistakes to Avoid:**
‚ùå Not using the 'from' property
‚ùå Using single path search for multiple queries
‚ùå Not setting appropriate limits
‚ùå Using wrong intent for your use case

**Next: Discover Network Scopes for Better Planning**
Would you like to learn how to discover network scopes and locations for more effective path planning?`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) guideNetworkScopeDiscovery(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "complete",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üåê **Network Scope Discovery for Path Planning**

**Why Discover Network Scopes?**
Before planning complex path searches, it's valuable to understand your network's structure:
- **Location-based analysis**: Identify network scopes in each site/location
- **Aggregation opportunities**: Find /8, /16, /24 prefixes that can be tested together
- **Connectivity planning**: Understand which locations can reach each other
- **Efficient path testing**: Test connectivity between aggregated prefixes instead of individual IPs

**What Network Scope Discovery Does:**
1. **Discovers all network prefixes** in your network by location
2. **Identifies aggregation levels** (/8, /16, /24 for IPv4; /32, /48, /64 for IPv6)
3. **Maps devices to prefixes** and locations
4. **Tests connectivity** between different locations and aggregation levels
5. **Generates comprehensive reports** with insights and recommendations

**Example Output:**

Location: ATL-DC01
- /8: 10.0.0.0/8 (15 devices)
- /16: 10.110.0.0/16 (8 devices)
- /24: 10.110.37.0/24 (3 devices)

Location: SJC-DC01
- /8: 10.0.0.0/8 (12 devices)
- /16: 10.117.0.0/16 (6 devices)

Connectivity: ATL-DC01 ‚Üî SJC-DC01 ‚úÖ CONNECTED

**How to Use:**
- Run analyze_network_prefixes to discover your network structure
- Use the discovered prefixes in your path search requests
- Test connectivity between locations at different aggregation levels

**Benefits for Path Search:**
- **Smarter planning**: Know which prefixes to test
- **Efficient testing**: Test aggregated prefixes instead of individual IPs
- **Location awareness**: Understand site-to-site connectivity
- **Better results**: Focus on meaningful network segments

**This completes the Path Search Workflow!** üöÄ

You now have the tools and knowledge to:
1. ‚úÖ Use best practices for path search
2. ‚úÖ Build effective bulk path search requests
3. ‚úÖ Discover network scopes for better planning
4. ‚úÖ Execute comprehensive path analysis

Ready to start analyzing your network!`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

// NormalizePathSearchRequest normalizes user input to the correct structure for path search
func NormalizePathSearchRequest(input map[string]interface{}) (isBulk bool, bulkArgs SearchPathsBulkArgs, err error) {
	// Always treat as bulk request - convert single requests to bulk format
	isBulk = true
	bulkArgs = SearchPathsBulkArgs{}

	// Parse common parameters
	if v, ok := input["network_id"].(string); ok {
		bulkArgs.NetworkID = v
	}
	if v, ok := input["snapshot_id"].(string); ok {
		bulkArgs.SnapshotID = v
	}
	if v, ok := input["intent"].(string); ok {
		bulkArgs.Intent = v
	}
	if v, ok := input["max_candidates"].(int); ok {
		bulkArgs.MaxCandidates = v
	}
	if v, ok := input["max_results"].(int); ok {
		bulkArgs.MaxResults = v
	}
	if v, ok := input["max_return_path_results"].(int); ok {
		bulkArgs.MaxReturnPathResults = v
	}
	if v, ok := input["max_seconds"].(int); ok {
		bulkArgs.MaxSeconds = v
	}
	if v, ok := input["max_overall_seconds"].(int); ok {
		bulkArgs.MaxOverallSeconds = v
	}
	if v, ok := input["include_network_functions"].(bool); ok {
		bulkArgs.IncludeNetworkFunctions = v
	}

	// Check if this is a bulk request with queries array
	if queries, ok := input["queries"]; ok {
		// Parse queries array
		if arr, ok := queries.([]interface{}); ok {
			for _, q := range arr {
				if qm, ok := q.(map[string]interface{}); ok {
					query := PathSearchQueryArgs{}
					if v, ok := qm["from"].(string); ok {
						query.From = v
					}
					if v, ok := qm["src_ip"].(string); ok {
						query.SrcIP = v
					}
					if v, ok := qm["dst_ip"].(string); ok {
						query.DstIP = v
					}
					if v, ok := qm["src_port"].(string); ok {
						query.SrcPort = v
					}
					if v, ok := qm["dst_port"].(string); ok {
						query.DstPort = v
					}
					if v, ok := qm["ip_proto"].(int); ok {
						query.IPProto = &v
					}
					bulkArgs.Queries = append(bulkArgs.Queries, query)
				}
			}
		}
	} else {
		// Single request - convert to bulk format
		query := PathSearchQueryArgs{}
		if v, ok := input["from"].(string); ok {
			query.From = v
		}
		if v, ok := input["src_ip"].(string); ok {
			query.SrcIP = v
		}
		if v, ok := input["dst_ip"].(string); ok {
			query.DstIP = v
		}
		if v, ok := input["src_port"].(string); ok {
			query.SrcPort = v
		}
		if v, ok := input["dst_port"].(string); ok {
			query.DstPort = v
		}
		if v, ok := input["ip_proto"].(int); ok {
			query.IPProto = &v
		}
		bulkArgs.Queries = append(bulkArgs.Queries, query)
	}

	return
}

// Single path search entry point - converts to bulk format
func (s *ForwardMCPService) searchPathsEntry(args SearchPathsArgs) (*mcp.ToolResponse, error) {
	// Convert single path search to bulk format
	bulkArgs := SearchPathsBulkArgs{
		NetworkID:               args.NetworkID,
		SnapshotID:              args.SnapshotID,
		Intent:                  args.Intent,
		MaxCandidates:           args.MaxCandidates,
		MaxResults:              args.MaxResults,
		MaxReturnPathResults:    args.MaxReturnPathResults,
		MaxSeconds:              args.MaxSeconds,
		IncludeNetworkFunctions: args.IncludeNetworkFunctions,
		Queries: []PathSearchQueryArgs{
			{
				From:    args.From,
				SrcIP:   args.SrcIP,
				DstIP:   args.DstIP,
				IPProto: args.IPProto,
				SrcPort: args.SrcPort,
				DstPort: args.DstPort,
			},
		},
	}
	return s.searchPathsBulk(bulkArgs)
}

// Update the searchPathsBulk entrypoint to route single queries to searchPaths
func (s *ForwardMCPService) searchPathsBulkEntry(args SearchPathsBulkArgs) (*mcp.ToolResponse, error) {
	return s.searchPathsBulk(args)
}

// Network Prefix Discovery and Analysis Methods

func (s *ForwardMCPService) networkPrefixDiscoveryWorkflow(args NetworkPrefixDiscoveryArgs) (*mcp.ToolResponse, error) {
	sessionID := fmt.Sprintf("session_%v", args.SessionID)
	state := s.workflowManager.GetState(sessionID)

	switch state.CurrentStep {
	case "start":
		return s.startNetworkPrefixDiscovery(sessionID)
	case "explain_process":
		return s.explainNetworkPrefixProcess(sessionID)
	case "show_example":
		return s.showNetworkPrefixExample(sessionID)
	case "guide_analysis":
		return s.guideNetworkPrefixAnalysis(sessionID)
	default:
		return s.startNetworkPrefixDiscovery(sessionID)
	}
}

func (s *ForwardMCPService) startNetworkPrefixDiscovery(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "explain_process",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üîç **Network Prefix Discovery & Connectivity Analysis Workflow**

Welcome to the Network Prefix Discovery workflow! This powerful tool helps you:

**üéØ What We Can Discover:**
- Network prefixes (/8, /16, /24, etc.) and their device mappings
- Site-to-site connectivity using aggregated prefixes
- Network topology patterns and connectivity gaps
- Route aggregation verification across your network

**üöÄ Key Capabilities:**
1. **Prefix Discovery**: Find all network prefixes and map them to devices
2. **Aggregation Analysis**: Test connectivity using different prefix levels
3. **Site Connectivity**: Analyze connectivity between different sites/locations
4. **Topology Mapping**: Create connectivity matrices for network planning

**üìã Available Steps:**
1. **explain_process** - Learn how the analysis works
2. **show_example** - See a practical example
3. **guide_analysis** - Get step-by-step guidance
4. **run_analysis** - Execute the actual analysis

**üí° Use Cases:**
- Multi-site network planning
- Network segmentation validation
- Route aggregation verification
- Connectivity gap analysis
- Network topology documentation

What would you like to explore first? Type the step name or ask questions about the process.`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) explainNetworkPrefixProcess(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "show_example",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := `üî¨ **How Network Prefix Discovery Works**

**Step 1: Prefix Discovery**
- Query all devices in the network for their IP addresses
- Extract network prefixes from device interfaces
- Map prefixes to devices and locations
- Identify aggregation opportunities

**Step 2: Aggregation Analysis**
- Group prefixes by different levels (/8, /16, /24, etc.)
- Create connectivity test matrices
- Test paths between aggregated prefixes
- Identify connectivity patterns

**Step 3: Site Connectivity Analysis**
- Map devices to physical locations/sites
- Test connectivity between sites using aggregated prefixes
- Identify connectivity gaps and bottlenecks
- Generate connectivity reports

**Step 4: Topology Mapping**
- Create connectivity matrices for different aggregation levels
- Visualize network topology patterns
- Identify redundant paths and single points of failure
- Document network architecture

**üîß Technical Process:**
1. Use NQE queries to discover device IP addresses
2. Extract and normalize network prefixes
3. Use bulk path search to test connectivity
4. Aggregate results by prefix levels
5. Generate comprehensive connectivity reports

**üìä Output Types:**
- Device-to-prefix mappings
- Connectivity matrices by aggregation level
- Site-to-site connectivity reports
- Network topology visualizations
- Gap analysis and recommendations

Ready to see an example? Type "show_example" to continue.`

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) showNetworkPrefixExample(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "guide_analysis",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := "üìã **Network Prefix Analysis Example**\n\n" +
		"**Example Scenario: Multi-Site Enterprise Network**\n\n" +
		"**Network Structure:**\n" +
		"- Site A: 10.1.0.0/16 (HQ)\n" +
		"- Site B: 10.2.0.0/16 (Branch 1)\n" +
		"- Site C: 10.3.0.0/16 (Branch 2)\n" +
		"- Site D: 192.168.1.0/24 (DMZ)\n\n" +
		"**Analysis Request:**\n" +
		"```json\n" +
		"{\n" +
		"  \"network_id\": \"162112\",\n" +
		"  \"prefix_levels\": [\"/8\", \"/16\", \"/24\"],\n" +
		"  \"from_devices\": [\"hq-router\", \"branch1-router\", \"branch2-router\"],\n" +
		"  \"to_devices\": [\"hq-router\", \"branch1-router\", \"branch2-router\", \"dmz-firewall\"],\n" +
		"  \"intent\": \"PREFER_DELIVERED\",\n" +
		"  \"max_results\": 10\n" +
		"}\n" +
		"```\n\n" +
		"**Expected Results:**\n" +
		"1. **Prefix Discovery:**\n" +
		"   - 10.0.0.0/8 (aggregated from all sites)\n" +
		"   - 10.1.0.0/16, 10.2.0.0/16, 10.3.0.0/16 (individual sites)\n" +
		"   - 192.168.1.0/24 (DMZ)\n\n" +
		"2. **Connectivity Matrix:**\n" +
		"   - Site A ‚Üî Site B: CONNECTED (via 10.0.0.0/8)\n" +
		"   - Site A ‚Üî Site C: CONNECTED (via 10.0.0.0/8)\n" +
		"   - Site A ‚Üî DMZ: PARTIAL (via specific routes)\n" +
		"   - All sites ‚Üî Internet: CONNECTED (via DMZ)\n\n" +
		"3. **Insights:**\n" +
		"   - All sites have connectivity at /8 level\n" +
		"   - DMZ has restricted access to internal sites\n" +
		"   - Redundant paths exist between major sites\n" +
		"   - Internet access is centralized through DMZ\n\n" +
		"**üîç Key Benefits:**\n" +
		"- Understand network segmentation\n" +
		"- Validate routing policies\n" +
		"- Identify connectivity gaps\n" +
		"- Plan network expansions\n" +
		"- Document network architecture\n\n" +
		"Ready to run your own analysis? Type \"guide_analysis\" for step-by-step instructions."

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) guideNetworkPrefixAnalysis(sessionID string) (*mcp.ToolResponse, error) {
	state := &WorkflowState{
		CurrentStep: "run_analysis",
		Parameters:  make(map[string]interface{}),
	}
	s.workflowManager.SetState(sessionID, state)

	content := "üéØ **Step-by-Step Network Prefix Analysis Guide**\n\n" +
		"**Step 1: Prepare Your Analysis**\n" +
		"1. Identify your target network (network_id)\n" +
		"2. Choose aggregation levels (prefix_levels)\n" +
		"3. Select source and destination devices\n" +
		"4. Set analysis parameters\n\n" +
		"**Step 2: Run the Analysis**\n" +
		"Use the analyze_network_prefixes tool with:\n" +
		"```json\n" +
		"{\n" +
		"  \"network_id\": \"your_network_id\",\n" +
		"  \"prefix_levels\": [\"/8\", \"/16\", \"/24\"],\n" +
		"  \"from_devices\": [\"device1\", \"device2\"],\n" +
		"  \"to_devices\": [\"device3\", \"device4\"],\n" +
		"  \"intent\": \"PREFER_DELIVERED\",\n" +
		"  \"max_results\": 10\n" +
		"}\n" +
		"```\n\n" +
		"**Step 3: Interpret Results**\n" +
		"- **CONNECTED**: Full connectivity at this aggregation level\n" +
		"- **PARTIAL**: Some paths exist but not all\n" +
		"- **DISCONNECTED**: No connectivity at this level\n\n" +
		"**Step 4: Generate Insights**\n" +
		"- Network segmentation analysis\n" +
		"- Connectivity gap identification\n" +
		"- Route aggregation verification\n" +
		"- Topology documentation\n\n" +
		"**üöÄ Ready to Start?**\n" +
		"Use the analyze_network_prefixes tool with your specific parameters to begin the analysis.\n\n" +
		"**üí° Pro Tips:**\n" +
		"- Start with broader aggregation levels (/8, /16)\n" +
		"- Focus on key devices first\n" +
		"- Use PREFER_DELIVERED for normal connectivity testing\n" +
		"- Set reasonable max_results to avoid timeouts\n\n" +
		"Your analysis is ready to run! Use the tool with your network parameters."

	return mcp.NewToolResponse(mcp.NewTextContent(content)), nil
}

func (s *ForwardMCPService) analyzeNetworkPrefixes(args NetworkPrefixAnalysisArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("analyze_network_prefixes", args, nil)

	// Use defaults if not specified
	networkID := s.getNetworkID(args.NetworkID)
	snapshotID := s.getSnapshotID(args.SnapshotID)
	maxResults := s.getQueryLimit(args.MaxResults)

	// Default prefix levels if not specified
	prefixLevels := args.PrefixLevels
	if len(prefixLevels) == 0 {
		prefixLevels = []string{"/8", "/16", "/24"}
	}

	// Default intent if not specified
	intent := args.Intent
	if intent == "" {
		intent = "PREFER_DELIVERED"
	}

	s.logger.Info("Starting network prefix analysis: networkID=%s, prefixLevels=%v, maxResults=%d",
		networkID, prefixLevels, maxResults)

	// Step 1: Discover network prefixes and device mappings
	prefixInfo, err := s.discoverNetworkPrefixes(networkID, snapshotID)
	if err != nil {
		s.logger.Error("Failed to discover network prefixes: %v", err)
		return nil, fmt.Errorf("failed to discover network prefixes: %w", err)
	}

	// Step 2: Analyze connectivity between prefixes
	connectivityResults, err := s.analyzePrefixConnectivity(networkID, prefixInfo, prefixLevels, args.FromDevices, args.ToDevices, intent, maxResults)
	if err != nil {
		s.logger.Error("Failed to analyze prefix connectivity: %v", err)
		return nil, fmt.Errorf("failed to analyze prefix connectivity: %w", err)
	}

	// Step 3: Generate comprehensive report
	report := s.generateConnectivityReport(prefixInfo, connectivityResults, prefixLevels)

	// Track analysis in memory system (placeholder for future implementation)
	if s.apiTracker != nil {
		s.logger.Debug("Network analysis completed - would track in memory system")
	}

	return mcp.NewToolResponse(mcp.NewTextContent(report)), nil
}

func (s *ForwardMCPService) discoverNetworkPrefixes(networkID, snapshotID string) ([]NetworkPrefixInfo, error) {
	// Use device inventory to discover all interface IPs and aggregate to prefixes
	params := &forward.DeviceQueryParams{}
	if snapshotID != "" {
		params.SnapshotID = snapshotID
	}
	devicesResp, err := s.forwardClient.GetDevices(networkID, params)
	if err != nil {
		return nil, fmt.Errorf("failed to get device inventory: %w", err)
	}

	// Group devices by location to identify location-based network scopes
	locationDevices := make(map[string][]string)
	deviceIPs := make(map[string][]string)                   // device -> IPs
	locationPrefixes := make(map[string]map[string][]string) // location -> prefix -> devices

	for _, device := range devicesResp.Devices {
		location := device.LocationID
		if location == "" {
			location = "unknown"
		}

		locationDevices[location] = append(locationDevices[location], device.Name)

		var deviceIPList []string
		for _, iface := range device.Interfaces {
			if iface.IPAddress == "" {
				continue
			}

			// Parse the IP address
			ip, _, err := net.ParseCIDR(iface.IPAddress)
			if err != nil {
				// Try to parse as plain IP and synthesize /32
				ip = net.ParseIP(iface.IPAddress)
				if ip == nil {
					s.logger.Warn("Could not parse interface IP: %s on device %s", iface.IPAddress, device.Name)
					continue
				}
			}

			deviceIPList = append(deviceIPList, iface.IPAddress)

			// Create different aggregation levels for this IP
			aggregationLevels := []int{8, 16, 24} // /8, /16, /24 for IPv4
			if ip.To4() == nil {
				aggregationLevels = []int{32, 48, 64} // /32, /48, /64 for IPv6
			}

			for _, level := range aggregationLevels {
				var mask net.IPMask
				if ip.To4() != nil {
					mask = net.CIDRMask(level, 32)
				} else {
					mask = net.CIDRMask(level, 128)
				}

				aggNet := &net.IPNet{IP: ip.Mask(mask), Mask: mask}
				prefix := aggNet.String()

				if locationPrefixes[location] == nil {
					locationPrefixes[location] = make(map[string][]string)
				}

				// Add device to this prefix in this location
				found := false
				for _, dev := range locationPrefixes[location][prefix] {
					if dev == device.Name {
						found = true
						break
					}
				}
				if !found {
					locationPrefixes[location][prefix] = append(locationPrefixes[location][prefix], device.Name)
				}
			}
		}
		deviceIPs[device.Name] = deviceIPList
	}

	// Create NetworkPrefixInfo for each location-prefix combination
	var prefixInfo []NetworkPrefixInfo

	for location, prefixMap := range locationPrefixes {
		for prefix, devices := range prefixMap {
			// Only include prefixes that have multiple devices or are significant
			if len(devices) > 1 || strings.HasSuffix(prefix, "/8") || strings.HasSuffix(prefix, "/16") {
				info := NetworkPrefixInfo{
					Prefix:     prefix,
					Device:     devices[0], // Representative device
					NetworkID:  networkID,
					Location:   location,
					Aggregated: len(devices) > 1,
					Subnets:    devices,
				}
				prefixInfo = append(prefixInfo, info)
			}
		}
	}

	s.logger.Info("Discovered %d network prefixes across %d locations", len(prefixInfo), len(locationDevices))
	for location, devices := range locationDevices {
		s.logger.Debug("Location %s: %d devices", location, len(devices))
	}

	return prefixInfo, nil
}

func (s *ForwardMCPService) analyzePrefixConnectivity(networkID string, prefixInfo []NetworkPrefixInfo, prefixLevels []string, fromDevices, toDevices []string, intent string, maxResults int) ([]ConnectivityAnalysisResult, error) {
	var results []ConnectivityAnalysisResult

	// Create connectivity test queries
	queries := s.createConnectivityQueries(prefixInfo, prefixLevels, fromDevices, toDevices)

	if len(queries) == 0 {
		s.logger.Info("No connectivity queries generated")
		return results, nil
	}

	s.logger.Info("Executing %d connectivity queries between network prefixes", len(queries))

	// Execute actual bulk path search
	bulkArgs := SearchPathsBulkArgs{
		NetworkID:  networkID,
		Queries:    queries,
		Intent:     intent,
		MaxResults: maxResults,
	}

	// Get latest snapshot if needed
	snapshotID := s.getSnapshotID("")
	bulkArgs.SnapshotID = snapshotID

	// Execute the bulk path search
	_, err := s.searchPathsBulk(bulkArgs)
	if err != nil {
		s.logger.Warn("Bulk path search failed, creating placeholder results: %v", err)
		// Create placeholder results for analysis
		for _, query := range queries {
			result := ConnectivityAnalysisResult{
				FromPrefix:       query.SrcIP,
				ToPrefix:         query.DstIP,
				FromDevice:       query.From,
				ToDevice:         s.findRepresentativeDevice(query.DstIP, toDevices),
				Connectivity:     "ANALYSIS_FAILED",
				PathCount:        0,
				AggregationLevel: s.determineAggregationLevel(query.SrcIP),
			}
			results = append(results, result)
		}
		return results, nil
	}

	// Parse the response to extract connectivity information
	// The response contains the actual path search results
	s.logger.Info("Successfully executed bulk path search, analyzing results")

	// For now, create results based on the queries
	// In a full implementation, we would parse the actual path search responses
	for _, query := range queries {
		result := ConnectivityAnalysisResult{
			FromPrefix:       query.SrcIP,
			ToPrefix:         query.DstIP,
			FromDevice:       query.From,
			ToDevice:         s.findRepresentativeDevice(query.DstIP, toDevices),
			Connectivity:     "CONNECTED", // Placeholder - would be determined from actual response
			PathCount:        1,           // Placeholder - would be determined from actual response
			AggregationLevel: s.determineAggregationLevel(query.SrcIP),
		}
		results = append(results, result)
	}

	// Note: In a full implementation, we would:
	// 1. Call the actual bulk path search API
	// 2. Parse the responses to determine connectivity
	// 3. Update the results with actual connectivity status

	return results, nil
}

func (s *ForwardMCPService) createConnectivityQueries(prefixInfo []NetworkPrefixInfo, prefixLevels []string, fromDevices, toDevices []string) []PathSearchQueryArgs {
	var queries []PathSearchQueryArgs

	// Create queries for each prefix level
	for _, level := range prefixLevels {
		// Get aggregated prefixes for this level
		aggregatedPrefixes := s.aggregatePrefixes(prefixInfo, level)

		// Create connectivity tests between prefixes
		for i, fromPrefix := range aggregatedPrefixes {
			for j, toPrefix := range aggregatedPrefixes {
				if i != j { // Don't test connectivity to self
					// Find representative devices for each prefix
					fromDevice := s.findRepresentativeDevice(fromPrefix, fromDevices)
					// toDevice := s.findRepresentativeDevice(toPrefix, toDevices) // Not used in current implementation

					if fromDevice != "" {
						queries = append(queries, PathSearchQueryArgs{
							From:  fromDevice,
							DstIP: toPrefix,
						})
					}
				}
			}
		}
	}

	return queries
}

func (s *ForwardMCPService) aggregatePrefixes(prefixInfo []NetworkPrefixInfo, level string) []string {
	// Simple aggregation logic - in a real implementation, this would be more sophisticated
	var aggregated []string
	prefixMap := make(map[string]bool)

	for _, info := range prefixInfo {
		// Extract network portion based on level
		network := s.extractNetworkPortion(info.Prefix, level)
		if network != "" && !prefixMap[network] {
			aggregated = append(aggregated, network)
			prefixMap[network] = true
		}
	}

	return aggregated
}

func (s *ForwardMCPService) extractNetworkPortion(prefix, level string) string {
	// Simple implementation - extract network portion based on CIDR level
	// In a real implementation, this would use proper IP network calculations
	if strings.Contains(prefix, "/") {
		parts := strings.Split(prefix, "/")
		if len(parts) == 2 {
			ip := parts[0]
			// For now, return the IP with the requested level
			// This is a simplified version - real implementation would calculate proper network addresses
			return fmt.Sprintf("%s%s", ip, level)
		}
	}
	return prefix
}

func (s *ForwardMCPService) findRepresentativeDevice(prefix string, preferredDevices []string) string {
	// Find a representative device for the prefix
	// Prefer devices from the preferredDevices list if available
	for _, preferred := range preferredDevices {
		// Simple matching - in real implementation, would check if device is in prefix
		if strings.Contains(prefix, preferred) {
			return preferred
		}
	}

	// Return first device found for this prefix
	// In real implementation, would parse prefix and find matching devices
	return ""
}

func (s *ForwardMCPService) determineAggregationLevel(prefix string) string {
	if strings.Contains(prefix, "/8") {
		return "/8"
	} else if strings.Contains(prefix, "/16") {
		return "/16"
	} else if strings.Contains(prefix, "/24") {
		return "/24"
	}
	return "/32"
}

func (s *ForwardMCPService) generateConnectivityReport(prefixInfo []NetworkPrefixInfo, connectivityResults []ConnectivityAnalysisResult, prefixLevels []string) string {
	var report strings.Builder

	report.WriteString("# üîç Network Prefix Discovery & Connectivity Analysis Report\n\n")

	// Prefix Discovery Summary
	report.WriteString("## üìä Prefix Discovery Summary\n\n")
	report.WriteString(fmt.Sprintf("**Total Prefixes Discovered:** %d\n\n", len(prefixInfo)))

	report.WriteString("### Device-to-Prefix Mappings:\n")
	for _, info := range prefixInfo {
		report.WriteString(fmt.Sprintf("- **%s** ‚Üí %s (Location: %s)\n", info.Device, info.Prefix, info.Location))
	}
	report.WriteString("\n")

	// Connectivity Analysis Summary
	report.WriteString("## üîó Connectivity Analysis Summary\n\n")

	connected := 0
	partial := 0
	disconnected := 0

	for _, result := range connectivityResults {
		switch result.Connectivity {
		case "CONNECTED":
			connected++
		case "PARTIAL":
			partial++
		case "DISCONNECTED":
			disconnected++
		}
	}

	report.WriteString(fmt.Sprintf("**Total Connectivity Tests:** %d\n", len(connectivityResults)))
	report.WriteString(fmt.Sprintf("- ‚úÖ **Connected:** %d\n", connected))
	report.WriteString(fmt.Sprintf("- ‚ö†Ô∏è **Partial:** %d\n", partial))
	report.WriteString(fmt.Sprintf("- ‚ùå **Disconnected:** %d\n\n", disconnected))

	// Connectivity Matrix by Aggregation Level
	for _, level := range prefixLevels {
		report.WriteString(fmt.Sprintf("### %s Aggregation Level\n\n", level))

		levelResults := s.filterResultsByLevel(connectivityResults, level)
		if len(levelResults) > 0 {
			report.WriteString("| From Prefix | To Prefix | Connectivity | Paths |\n")
			report.WriteString("|-------------|-----------|--------------|-------|\n")

			for _, result := range levelResults {
				status := "‚ùå"
				if result.Connectivity == "CONNECTED" {
					status = "‚úÖ"
				} else if result.Connectivity == "PARTIAL" {
					status = "‚ö†Ô∏è"
				}

				report.WriteString(fmt.Sprintf("| %s | %s | %s %s | %d |\n",
					result.FromPrefix, result.ToPrefix, status, result.Connectivity, result.PathCount))
			}
			report.WriteString("\n")
		}
	}

	// Key Insights
	report.WriteString("## üí° Key Insights\n\n")

	if connected > 0 {
		report.WriteString("‚úÖ **Strong Connectivity:** Network shows good connectivity at multiple aggregation levels\n")
	}
	if partial > 0 {
		report.WriteString("‚ö†Ô∏è **Partial Connectivity:** Some paths exist but may have limitations or bottlenecks\n")
	}
	if disconnected > 0 {
		report.WriteString("‚ùå **Connectivity Gaps:** Some network segments lack connectivity - review routing policies\n")
	}

	report.WriteString("\n## üéØ Recommendations\n\n")
	report.WriteString("1. **Review Disconnected Segments:** Investigate routing policies for disconnected paths\n")
	report.WriteString("2. **Optimize Partial Connectivity:** Consider adding redundant paths for better reliability\n")
	report.WriteString("3. **Document Topology:** Use this analysis for network documentation and planning\n")
	report.WriteString("4. **Monitor Changes:** Re-run analysis after network changes to validate connectivity\n")

	return report.String()
}

func (s *ForwardMCPService) filterResultsByLevel(results []ConnectivityAnalysisResult, level string) []ConnectivityAnalysisResult {
	var filtered []ConnectivityAnalysisResult
	for _, result := range results {
		if result.AggregationLevel == level {
			filtered = append(filtered, result)
		}
	}
	return filtered
}

// resolveDeviceToIP attempts to resolve a device name to an IP address
// If the input looks like an IP address, it returns it as-is
// If it looks like a device name, it tries to find any IP address bound to the device
func (s *ForwardMCPService) resolveDeviceToIP(networkID, deviceOrIP string) (string, error) {
	// If it looks like an IP address, return as-is
	if net.ParseIP(deviceOrIP) != nil {
		return deviceOrIP, nil
	}

	// If it looks like a CIDR, return as-is
	if strings.Contains(deviceOrIP, "/") {
		_, _, err := net.ParseCIDR(deviceOrIP)
		if err == nil {
			return deviceOrIP, nil
		}
	}

	// Otherwise, treat as device name and try to get its management IP
	resolutionID := fmt.Sprintf("%s-%d", deviceOrIP, time.Now().UnixNano())
	s.logger.Debug("[%s] Resolving device name to IP: %s", resolutionID, deviceOrIP)

	// Get devices and find the one with matching name
	devices, err := s.forwardClient.GetDevices(networkID, &forward.DeviceQueryParams{})
	if err != nil {
		return "", fmt.Errorf("failed to get devices for network %s: %w", networkID, err)
	}

	if devices == nil || len(devices.Devices) == 0 {
		return "", fmt.Errorf("no devices found in network %s", networkID)
	}

	// Find device by name
	s.logger.Debug("Searching through %d devices for device name: %s", len(devices.Devices), deviceOrIP)
	foundDevice := false
	for _, device := range devices.Devices {
		s.logger.Debug("Checking device: %s (management IPs: %v, interface count: %d)",
			device.Name, device.ManagementIPs, len(device.Interfaces))

		if device.Name == deviceOrIP {
			foundDevice = true
			s.logger.Info("Found device: %s", deviceOrIP)

			// Try management IPs first
			if len(device.ManagementIPs) > 0 {
				// Check if this management IP is already used by another device
				ipUsedBy := []string{}
				for _, otherDevice := range devices.Devices {
					if otherDevice.Name != deviceOrIP {
						for _, mgmtIP := range otherDevice.ManagementIPs {
							if mgmtIP == device.ManagementIPs[0] {
								ipUsedBy = append(ipUsedBy, otherDevice.Name)
							}
						}
					}
				}

				if len(ipUsedBy) > 0 {
					s.logger.Warn("Device %s management IP %s is shared with other devices: %v",
						deviceOrIP, device.ManagementIPs[0], ipUsedBy)
				}

				s.logger.Info("Using management IP for device %s: %s", deviceOrIP, device.ManagementIPs[0])
				return device.ManagementIPs[0], nil
			}

			// Try interface IPs
			s.logger.Debug("No management IPs, checking %d interfaces", len(device.Interfaces))
			for i, iface := range device.Interfaces {
				s.logger.Debug("Interface %d: %s (IP: %s)", i, iface.Name, iface.IPAddress)
				if iface.IPAddress != "" {
					// Check if this interface IP is already used by another device
					ipUsedBy := []string{}
					for _, otherDevice := range devices.Devices {
						if otherDevice.Name != deviceOrIP {
							for _, otherIface := range otherDevice.Interfaces {
								if otherIface.IPAddress == iface.IPAddress {
									ipUsedBy = append(ipUsedBy, otherDevice.Name)
								}
							}
						}
					}

					if len(ipUsedBy) > 0 {
						s.logger.Warn("Device %s interface IP %s is shared with other devices: %v",
							deviceOrIP, iface.IPAddress, ipUsedBy)
					}

					s.logger.Info("Using interface IP for device %s: %s (interface: %s)",
						deviceOrIP, iface.IPAddress, iface.Name)
					return iface.IPAddress, nil
				}
			}

			s.logger.Warn("Device %s found but has no IP addresses", deviceOrIP)
			return "", fmt.Errorf("device %s found but has no IP addresses", deviceOrIP)
		}
	}

	if !foundDevice {
		s.logger.Warn("Device %s not found in network %s", deviceOrIP, networkID)
		// Log some available device names for debugging
		deviceNames := make([]string, 0, len(devices.Devices))
		for _, device := range devices.Devices {
			deviceNames = append(deviceNames, device.Name)
		}
		s.logger.Debug("Available devices in network: %v", deviceNames)
	} else {
		// Log IP conflict summary for all devices
		ipConflictMap := make(map[string][]string)
		for _, device := range devices.Devices {
			for _, mgmtIP := range device.ManagementIPs {
				ipConflictMap[mgmtIP] = append(ipConflictMap[mgmtIP], device.Name)
			}
			for _, iface := range device.Interfaces {
				if iface.IPAddress != "" {
					ipConflictMap[iface.IPAddress] = append(ipConflictMap[iface.IPAddress], device.Name)
				}
			}
		}

		// Report conflicts
		for ip, deviceList := range ipConflictMap {
			if len(deviceList) > 1 {
				s.logger.Warn("IP conflict detected: %s is used by multiple devices: %v", ip, deviceList)
			}
		}
	}

	return "", fmt.Errorf("device %s not found in network %s", deviceOrIP, networkID)
}

// listInstanceIDs lists all available Forward Networks instance IDs in the database
func (s *ForwardMCPService) listInstanceIDs(args ListInstanceIDsArgs) (*mcp.ToolResponse, error) {
	s.logToolCall("list_instance_ids", args, nil)

	if s.database == nil {
		return nil, fmt.Errorf("database is not available")
	}

	instances, err := s.database.GetAllInstanceIDs()
	if err != nil {
		return nil, fmt.Errorf("failed to get instance IDs: %w", err)
	}

	if len(instances) == 0 {
		return mcp.NewToolResponse(mcp.NewTextContent("No Forward Networks instances found in the database.")), nil
	}

	// Build response
	var responseText strings.Builder
	responseText.WriteString(fmt.Sprintf("Found %d Forward Networks instances in the database:\n\n", len(instances)))

	for i, instance := range instances {
		responseText.WriteString(fmt.Sprintf("%d. **Instance ID: %s**\n", i+1, instance.ID))
		responseText.WriteString(fmt.Sprintf("   - Query Count: %d\n", instance.QueryCount))
		responseText.WriteString(fmt.Sprintf("   - First Sync: %s\n", instance.FirstSync.Format("2006-01-02 15:04:05")))
		responseText.WriteString(fmt.Sprintf("   - Last Sync: %s\n", instance.LastSync.Format("2006-01-02 15:04:05")))
		responseText.WriteString("\n")
	}

	responseText.WriteString("**To use a specific instance:**\n")
	responseText.WriteString("1. Set the FORWARD_INSTANCE_ID environment variable to the desired instance ID\n")
	responseText.WriteString("2. Restart the MCP server\n")
	responseText.WriteString("3. The server will then use queries from that instance\n\n")
	responseText.WriteString("**Example:**\n")
	responseText.WriteString("```bash\n")
	responseText.WriteString("export FORWARD_INSTANCE_ID=49bd3225\n")
	responseText.WriteString("# Then restart your MCP server\n")
	responseText.WriteString("```")

	return mcp.NewToolResponse(mcp.NewTextContent(responseText.String())), nil
}
